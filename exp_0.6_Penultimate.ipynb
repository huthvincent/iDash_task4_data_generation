{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb655cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models_lib\n",
    "import resnet_cifar10\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.transforms import functional as vF\n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os \n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as ds\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.models as models_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03bda9",
   "metadata": {},
   "source": [
    "# hyper para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cca2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse para\n",
    "noise_mu = 3\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac657f",
   "metadata": {},
   "source": [
    "# Penultimate layer distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77238f",
   "metadata": {},
   "source": [
    "## model. arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc841e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = models_lib.vgg16(pretrained=False, progress=False, num_classes=10)\n",
    "# net._modules['avgpool'] = torch.nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "# net._modules['classifier'][0] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][3] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][6] = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "# for i,channel in enumerate(cfg[net_name]):\n",
    "#     if channel != 'M':\n",
    "#         intermediate_result[str(i)] = []\n",
    "# intermediate_result[\"linear\"] = []        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "            \n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "net = VGG(net_name)\n",
    "# print(net)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a69e59",
   "metadata": {},
   "source": [
    "## reverse tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c68544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oneone(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor*2.0-1.0\n",
    "        # return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        Oneone(),\n",
    "    ]\n",
    ")\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    Oneone(),\n",
    "])\n",
    "class AttackCIFAR10(CIFAR10):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "            source_label: int = None,\n",
    "            target_label: int = None,\n",
    "            max_num: int = None,\n",
    "    ) -> None:\n",
    "        super(AttackCIFAR10, self).__init__(root, train=train, transform=transform,\n",
    "                                            target_transform=target_transform,\n",
    "                                            download=download)\n",
    "        self.all_data = None\n",
    "        self.all_targets = None\n",
    "        if source_label is not None:\n",
    "            self._select(source_label, max_num)\n",
    "            self.targets[:] = target_label\n",
    "\n",
    "    def _select(self, label, max_num=None):\n",
    "        if self.all_data is None:\n",
    "            self.all_data = self.data.copy()\n",
    "            self.all_targets = self.targets.copy()\n",
    "        else:\n",
    "            self.data = self.all_data.copy()\n",
    "            self.targets = self.all_targets.copy()\n",
    "\n",
    "        np_targets = np.asarray(self.targets)\n",
    "        lb_index = (np_targets == label)\n",
    "        assert np.sum(lb_index) > 0, \"No data with label %d\" % label\n",
    "\n",
    "        self.targets = np_targets[lb_index]\n",
    "        self.data = self.data[lb_index]\n",
    "\n",
    "        if max_num is not None:\n",
    "            n = len(self.data)\n",
    "            sl_index = np.random.permutation(n)[:max_num]\n",
    "            self.targets = np_targets[sl_index]\n",
    "            self.data = self.data[sl_index]\n",
    "\n",
    "\n",
    "def load_model(model_class, ckpt_path, device):\n",
    "    net = VGG(net_name)\n",
    "    # net = model_class(num_classes=10)\n",
    "    net.to(device)\n",
    "    if device == 'cuda':\n",
    "#         net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "    # Load checkpoint.\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     best_acc = checkpoint['acc']\n",
    "#     start_epoch = checkpoint['epoch']\n",
    "\n",
    "#     print('successfully load model from %s with best acc %f on epoch %d' % (ckpt_path, best_acc, start_epoch))\n",
    "\n",
    "#     return net, best_acc, start_epoch\n",
    "    return net\n",
    "\n",
    "inputs_mean = [0.4914, 0.4822, 0.4465]\n",
    "inputs_std = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "\n",
    "def test_acc(model_path):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    trainset = CIFAR10(\n",
    "        root='./data', train=True, download=True,\n",
    "        transform=transform_train, )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "    net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "\n",
    "    crt, tot = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        preds = torch.argmax(outputs, axis=1)\n",
    "        crt += torch.sum(preds == targets)\n",
    "        tot += len(preds)\n",
    "    print('acc :', crt / tot *100)\n",
    "\n",
    "\n",
    "def train(source_label, target_label, max_epoch, model_path, max_training_samples=None):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    trainset = AttackCIFAR10(\n",
    "        root='./data', train=True, download=True,\n",
    "        transform=transform_train,\n",
    "        source_label=source_label, target_label=target_label,\n",
    "        max_num=max_training_samples)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net.eval()\n",
    "\n",
    "    eps = 1e-6\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    mask_tanh = np.ones([1, 32, 32], dtype=np.float32) * -4\n",
    "    # pattern_tanh = np.zeros([3, 32, 32], dtype=np.float32)\n",
    "    pattern_tanh = np.random.rand(3, 32, 32).astype(np.float32) / 8 - (1 / 8 / 2)\n",
    "    mask_tanh_tensor = Variable(torch.from_numpy(mask_tanh), requires_grad=True)\n",
    "    pattern_tanh_tensor = Variable(torch.from_numpy(pattern_tanh), requires_grad=True)\n",
    "    opt = torch.optim.Adam([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.9))\n",
    "#     opt = torch.optim.Adamax([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.999))\n",
    "#     opt = torch.optim.AdamW([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.999))\n",
    "#     opt = torch.optim.Adagrad([pattern_tanh_tensor, mask_tanh_tensor], lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "#     opt = torch.optim.Adadelta([pattern_tanh_tensor, mask_tanh_tensor], lr=2, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "#     opt = torch.optim.LBFGS([pattern_tanh_tensor, mask_tanh_tensor], lr=1, max_iter=100, max_eval=None, tolerance_grad=1e-05, tolerance_change=1e-09, history_size=100, line_search_fn=None)\n",
    "    \n",
    "#     opt = torch.optim.ASGD([pattern_tanh_tensor, mask_tanh_tensor], lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "#     opt = torch.optim.SGD([pattern_tanh_tensor, mask_tanh_tensor], lr=1)\n",
    "    \n",
    "    tlab = np.zeros([1, 10], dtype=np.int32)\n",
    "    tlab[0, target_label] = 1\n",
    "    tlab_tensor = torch.from_numpy(tlab).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
    "    #                       momentum=0.9, weight_decay=5e-4)\n",
    "    for epoch in range(max_epoch):\n",
    "        print('epoch %d' % epoch)\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "\n",
    "            mask_tanh_tensor_dev = mask_tanh_tensor.to(device)\n",
    "            pattern_tanh_tensor_dev = pattern_tanh_tensor.to(device)\n",
    "            mask_tensor_dev = torch.tanh(mask_tanh_tensor_dev) / 2 + 0.5\n",
    "            pattern_tensor_dev = torch.tanh(pattern_tanh_tensor_dev) / 2 + 0.5\n",
    "\n",
    "            att_inputs = (1 - mask_tensor_dev) * inputs + mask_tensor_dev * pattern_tensor_dev\n",
    "            att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "            outputs = net(att_inputs)\n",
    "\n",
    "            '''\n",
    "            probs = torch.softmax(outputs, axis=-1)\n",
    "            real = torch.sum(tlab_tensor * probs, dim=1)\n",
    "            other, _ = torch.max((1 - tlab_tensor) * probs - tlab_tensor * 10000, dim=1)\n",
    "            at_loss = torch.mean(F.relu(other - real + 0.5))\n",
    "            at_data = at_loss.data\n",
    "            l1_loss = torch.sum(mask_tensor_dev)\n",
    "            loss = at_loss + 1e-3 * (0.001 / (at_data+1e-6)) * F.relu(l1_loss-10)\n",
    "            print(loss.item(), at_loss.item(), l1_loss.item())\n",
    "            # '''\n",
    "\n",
    "            # '''\n",
    "            ce_loss = criterion(outputs, targets)\n",
    "            ce_data = ce_loss.data\n",
    "            l1_loss = torch.sum(mask_tensor_dev)\n",
    "            loss = ce_loss + 1e-3 * (0.1 / ce_data) * F.relu(l1_loss - 10)\n",
    "            print(loss.item(), ce_loss.item(), l1_loss.item())\n",
    "            # loss = ce_loss\n",
    "            # print(loss.item())\n",
    "            # '''\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    mask_img = torch.tanh(mask_tanh_tensor) / 2 + 0.5\n",
    "    pattern_img = torch.tanh(pattern_tanh_tensor) / 2 + 0.5\n",
    "    merge_img = mask_img * pattern_img\n",
    "\n",
    "    rst_dict = {'mask': mask_img.detach().cpu().numpy(),\n",
    "                'pattern': pattern_img.detach().cpu().numpy()}\n",
    "    with open('trigger_pattern.pkl', 'wb') as f:\n",
    "        pickle.dump(rst_dict, f)\n",
    "\n",
    "    to_pil = ToPILImage()\n",
    "    mask_img_show = to_pil(mask_img)\n",
    "    pattern_img_show = to_pil(pattern_img)\n",
    "    merge_img_show = to_pil(merge_img)\n",
    "    pattern_img_show.save('pattern.png')\n",
    "    mask_img_show.save('mask.png')\n",
    "    merge_img_show.save('merge.png')\n",
    "\n",
    "    return mask_img, pattern_img\n",
    "\n",
    "\n",
    "def test(mask_tensor, pattern_tensor, source_label, target_label, model_path):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    testset = AttackCIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_train, source_label=source_label,\n",
    "        target_label=target_label)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    # mask_tensor = torch.from_numpy(mask).to(device)\n",
    "    # pattern_tensor = torch.from_numpy(pattern).to(device)\n",
    "    mask_tensor = mask_tensor.to(device)\n",
    "    pattern_tensor = pattern_tensor.to(device)\n",
    "\n",
    "    tot, crt = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "\n",
    "        att_inputs = (1 - mask_tensor) * inputs + mask_tensor * pattern_tensor\n",
    "        att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "\n",
    "        outputs = net(att_inputs)\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "        tot += len(preds)\n",
    "        crt += np.sum(preds == target_label)\n",
    "\n",
    "    print('test acc: %.2f%%' % (crt / tot * 100))\n",
    "    return crt / tot * 100\n",
    "\n",
    "def new_test(mask_tensor, pattern_tensor, source_label, target_label, net):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    testset = AttackCIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform_train, source_label=source_label,\n",
    "        target_label=target_label,max_num=10000)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = net.to(device)\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    # mask_tensor = torch.from_numpy(mask).to(device)\n",
    "    # pattern_tensor = torch.from_numpy(pattern).to(device)\n",
    "    mask_tensor = mask_tensor.to(device)\n",
    "    pattern_tensor = pattern_tensor.to(device)\n",
    "\n",
    "    tot, crt = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "#         print(inputs.shape)\n",
    "        att_inputs = (1 - mask_tensor) * inputs + mask_tensor * pattern_tensor\n",
    "        att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "#         for i in range(len(inputs)):\n",
    "#             img = np.transpose(att_inputs[i].cpu(),(1,2,0))\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "#             break\n",
    "        \n",
    "        outputs = net(att_inputs)\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "        tot += len(preds)\n",
    "        crt += np.sum(preds == target_label)\n",
    "        \n",
    "    print('test acc: %.2f%%' % (crt / tot * 100))\n",
    "    return crt / tot * 100\n",
    "    \n",
    "def load_pattern():\n",
    "    with open('trigger_pattern.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    mask, pattern = data['mask'], data['pattern']\n",
    "    mask_tensor = torch.from_numpy(mask)\n",
    "    pattern_tensor = torch.from_numpy(pattern)\n",
    "    return mask_tensor, pattern_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fdf0f3",
   "metadata": {},
   "source": [
    "## reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "514821ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "epoch 0\n",
      "8.215213775634766 8.215213775634766 0.3433837890625\n",
      "8.542034149169922 8.542034149169922 0.3476838767528534\n",
      "epoch 1\n",
      "8.360588073730469 8.360588073730469 0.3502812087535858\n",
      "8.43508529663086 8.43508529663086 0.35315999388694763\n",
      "epoch 2\n",
      "8.192403793334961 8.192403793334961 0.3566116690635681\n",
      "8.362798690795898 8.362798690795898 0.3592309355735779\n",
      "epoch 3\n",
      "8.328383445739746 8.328383445739746 0.3615255355834961\n",
      "8.509296417236328 8.509296417236328 0.36553457379341125\n",
      "epoch 4\n",
      "8.265033721923828 8.265033721923828 0.3715117573738098\n",
      "8.312763214111328 8.312763214111328 0.38134145736694336\n",
      "epoch 5\n",
      "8.144078254699707 8.144078254699707 0.39260345697402954\n",
      "8.431038856506348 8.431038856506348 0.4067263603210449\n",
      "epoch 6\n",
      "8.101786613464355 8.101786613464355 0.42345908284187317\n",
      "8.577278137207031 8.577278137207031 0.4441123902797699\n",
      "epoch 7\n",
      "8.189425468444824 8.189425468444824 0.4621584117412567\n",
      "8.50766658782959 8.50766658782959 0.48217180371284485\n",
      "epoch 8\n",
      "8.206332206726074 8.206332206726074 0.5133400559425354\n",
      "8.426867485046387 8.426867485046387 0.5498759150505066\n",
      "epoch 9\n",
      "8.243025779724121 8.243025779724121 0.5839167237281799\n",
      "8.354546546936035 8.354546546936035 0.6275918483734131\n",
      "epoch 10\n",
      "8.35263729095459 8.35263729095459 0.6796467900276184\n",
      "8.346163749694824 8.346163749694824 0.7510881423950195\n",
      "epoch 11\n",
      "8.135632514953613 8.135632514953613 0.8234425783157349\n",
      "8.553964614868164 8.553964614868164 0.9061482548713684\n",
      "epoch 12\n",
      "8.117812156677246 8.117812156677246 0.9968475103378296\n",
      "8.309290885925293 8.309290885925293 1.1017158031463623\n",
      "epoch 13\n",
      "7.981042861938477 7.981042861938477 1.2572205066680908\n",
      "8.427434921264648 8.427434921264648 1.4264767169952393\n",
      "epoch 14\n",
      "8.301350593566895 8.301350593566895 1.6100149154663086\n",
      "8.482098579406738 8.482098579406738 1.850700855255127\n",
      "epoch 15\n",
      "8.214012145996094 8.214012145996094 2.1415791511535645\n",
      "8.159385681152344 8.159385681152344 2.484375\n",
      "epoch 16\n",
      "8.215353012084961 8.215353012084961 2.817880630493164\n",
      "8.19394302368164 8.19394302368164 3.2923738956451416\n",
      "epoch 17\n",
      "7.934078693389893 7.934078693389893 3.87539005279541\n",
      "8.074819564819336 8.074819564819336 4.4947381019592285\n",
      "epoch 18\n",
      "7.583995819091797 7.583995819091797 5.061688423156738\n",
      "7.5846428871154785 7.5846428871154785 5.850852966308594\n",
      "epoch 19\n",
      "7.467991352081299 7.467991352081299 6.804927825927734\n",
      "7.772008895874023 7.772008895874023 7.8251872062683105\n",
      "epoch 20\n",
      "7.168689250946045 7.168689250946045 9.077018737792969\n",
      "7.12852144241333 7.128515243530273 10.434158325195312\n",
      "epoch 21\n",
      "6.8513970375061035 6.8513689041137695 11.938189506530762\n",
      "6.550479412078857 6.5504255294799805 13.543663024902344\n",
      "epoch 22\n",
      "6.635629653930664 6.635550498962402 15.26188850402832\n",
      "6.898854732513428 6.898752212524414 17.06058692932129\n",
      "epoch 23\n",
      "5.912996292114258 5.912845611572266 18.906211853027344\n",
      "6.732346534729004 6.732179164886475 21.256412506103516\n",
      "epoch 24\n",
      "5.817030429840088 5.8167948722839355 23.690290451049805\n",
      "5.9492597579956055 5.948988914489746 26.09847640991211\n",
      "epoch 25\n",
      "5.348158836364746 5.347808361053467 28.75035858154297\n",
      "5.525078296661377 5.524685859680176 31.681243896484375\n",
      "epoch 26\n",
      "4.858919143676758 4.858410835266113 34.690895080566406\n",
      "4.9882073402404785 4.987646102905273 37.995147705078125\n",
      "epoch 27\n",
      "4.346338748931885 4.345606327056885 41.82867431640625\n",
      "4.134178161621094 4.133317947387695 45.56151580810547\n",
      "epoch 28\n",
      "3.3416225910186768 3.3404412269592285 49.4599494934082\n",
      "3.6628129482269287 3.6616172790527344 53.78008270263672\n",
      "epoch 29\n",
      "3.17842960357666 3.17691707611084 58.054534912109375\n",
      "3.37656307220459 3.375006675720215 62.5287971496582\n",
      "epoch 30\n",
      "2.2144200801849365 2.2118165493011475 67.58317565917969\n",
      "2.0936667919158936 2.090672731399536 72.59356689453125\n",
      "epoch 31\n",
      "1.6529502868652344 1.648840069770813 77.76998138427734\n",
      "1.6751763820648193 1.6708073616027832 82.99783325195312\n",
      "epoch 32\n",
      "1.3650139570236206 1.3592759370803833 87.99554443359375\n",
      "1.0924180746078491 1.084740161895752 93.28578186035156\n",
      "epoch 33\n",
      "0.9454978108406067 0.9361310601234436 97.68508911132812\n",
      "1.041718602180481 1.0327728986740112 102.38920593261719\n",
      "epoch 34\n",
      "0.7798565626144409 0.7672539353370667 106.6942138671875\n",
      "0.520057737827301 0.4998057186603546 111.22084045410156\n",
      "epoch 35\n",
      "0.5417467355728149 0.5215272307395935 115.4501953125\n",
      "0.2893649935722351 0.24443848431110382 119.81767272949219\n",
      "epoch 36\n",
      "0.4253799021244049 0.396921306848526 122.95819091796875\n",
      "0.3391156494617462 0.3005050718784332 126.02677154541016\n",
      "epoch 37\n",
      "0.23973535001277924 0.16903303563594818 129.51025390625\n",
      "0.24802377820014954 0.17992475628852844 132.5269775390625\n",
      "epoch 38\n",
      "0.23676501214504242 0.08023001253604889 135.58804321289062\n",
      "0.24477466940879822 0.07542196661233902 137.7291259765625\n",
      "epoch 39\n",
      "0.35776039958000183 0.04082474857568741 139.38816833496094\n",
      "0.30842360854148865 0.05012035742402077 139.46249389648438\n",
      "epoch 40\n",
      "0.23403829336166382 0.08997092396020889 139.61874389648438\n",
      "0.28194719552993774 0.058325231075286865 140.4280242919922\n",
      "epoch 41\n",
      "0.2721593379974365 0.06276131421327591 141.4209442138672\n",
      "0.5729353427886963 0.024170272052288055 142.63800048828125\n",
      "epoch 42\n",
      "0.6899616718292236 0.01969064213335514 141.98065185546875\n",
      "1.7913416624069214 0.007274498697370291 139.78192138671875\n",
      "epoch 43\n",
      "0.6272898316383362 0.020314114168286324 133.30174255371094\n",
      "0.22385728359222412 0.08592907339334488 128.52041625976562\n",
      "epoch 44\n",
      "0.5959610939025879 0.020370297133922577 127.24954223632812\n",
      "0.23308981955051422 0.0712956041097641 125.35215759277344\n",
      "epoch 45\n",
      "3.336881160736084 0.0034540770575404167 125.1391372680664\n",
      "0.22191941738128662 0.07094047963619232 117.10517120361328\n",
      "epoch 46\n",
      "0.2035600244998932 0.10232207924127579 113.58875274658203\n",
      "0.23095941543579102 0.060453373938798904 113.07664489746094\n",
      "epoch 47\n",
      "0.24676641821861267 0.05339035764336586 113.24415588378906\n",
      "0.2556399405002594 0.05089075118303299 114.19839477539062\n",
      "epoch 48\n",
      "0.21578247845172882 0.07378928363323212 114.77576446533203\n",
      "0.30411577224731445 0.03998256102204323 115.60720825195312\n",
      "epoch 49\n",
      "0.5010591149330139 0.022212877869606018 116.36552429199219\n",
      "0.23897939920425415 0.05847404897212982 115.54878997802734\n",
      "epoch 50\n",
      "3.101229190826416 0.0034274659119546413 116.17608642578125\n",
      "0.20917101204395294 0.0717669427394867 108.61068725585938\n",
      "epoch 51\n",
      "0.196174755692482 0.10925782471895218 104.96354675292969\n",
      "0.24131833016872406 0.19217519462108612 104.44092559814453\n",
      "epoch 52\n",
      "0.19760961830615997 0.08449221402406693 105.57538604736328\n",
      "0.22998860478401184 0.056113190948963165 107.56704711914062\n",
      "epoch 53\n",
      "0.2280263900756836 0.058953531086444855 109.67442321777344\n",
      "1.0421980619430542 0.009822042658925056 111.40040588378906\n",
      "epoch 54\n",
      "2.2311484813690186 0.004473092500120401 109.60124206542969\n",
      "0.20602953433990479 0.06683038920164108 103.02731323242188\n",
      "epoch 55\n",
      "0.263394832611084 0.04065831005573273 100.56089782714844\n",
      "0.2252880036830902 0.051397502422332764 99.3753662109375\n",
      "epoch 56\n",
      "0.3673228621482849 0.026320524513721466 99.75360107421875\n",
      "0.4969359040260315 0.018712833523750305 99.48908233642578\n",
      "epoch 57\n",
      "0.3318580389022827 0.029431909322738647 99.00977325439453\n",
      "0.24104230105876923 0.0451897531747818 98.50527954101562\n",
      "epoch 58\n",
      "0.2740878164768219 0.03713475540280342 97.99192810058594\n",
      "3.157559633255005 0.0027942638844251633 98.15245819091797\n",
      "epoch 59\n",
      "0.1797047257423401 0.08353191614151001 90.33497619628906\n",
      "0.18263936042785645 0.11597274243831635 87.31509399414062\n",
      "epoch 60\n",
      "0.18033525347709656 0.10988236218690872 87.4153060913086\n",
      "0.2345319539308548 0.04048800468444824 88.56451416015625\n",
      "epoch 61\n",
      "0.1796736717224121 0.09892381727695465 89.88082885742188\n",
      "2.1238021850585938 0.0038560358807444572 91.74588012695312\n",
      "epoch 62\n",
      "2.082119941711426 0.003716816892847419 87.25043487548828\n",
      "0.17265485227108002 0.06608748435974121 80.42768859863281\n",
      "epoch 63\n",
      "0.17604553699493408 0.11894809454679489 77.91631317138672\n",
      "0.2088368833065033 0.1678466647863388 78.80072021484375\n",
      "epoch 64\n",
      "0.17259404063224792 0.10128536075353622 82.22523498535156\n",
      "0.19042302668094635 0.05609709024429321 85.35293579101562\n",
      "epoch 65\n",
      "0.2975156903266907 0.02891228161752224 87.65937042236328\n",
      "0.3857928216457367 0.021587174385786057 88.6217041015625\n",
      "epoch 66\n",
      "0.9625888466835022 0.008247479796409607 88.7091064453125\n",
      "0.2380717545747757 0.03834390640258789 86.58345031738281\n",
      "epoch 67\n",
      "1.194516658782959 0.006353046279400587 85.48458862304688\n",
      "0.4446825087070465 0.016839565709233284 82.04689025878906\n",
      "epoch 68\n",
      "0.3116426467895508 0.02430512011051178 79.83772277832031\n",
      "0.16690176725387573 0.09232595562934875 78.85282135009766\n",
      "epoch 69\n",
      "0.29839688539505005 0.025522815063595772 79.6451416015625\n",
      "0.29281002283096313 0.026369314640760422 80.25859069824219\n",
      "epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3215828239917755 0.023910967633128166 81.17620849609375\n",
      "1.6724703311920166 0.004271141719073057 81.25114440917969\n",
      "epoch 71\n",
      "0.17693401873111725 0.0543207973241806 76.60447692871094\n",
      "0.3877798020839691 0.017636768519878387 75.28126525878906\n",
      "epoch 72\n",
      "0.1686994731426239 0.11063248664140701 74.24095153808594\n",
      "0.3949557840824127 0.01738801784813404 75.65155029296875\n",
      "epoch 73\n",
      "0.1773706078529358 0.05267242342233658 75.68154907226562\n",
      "0.38594043254852295 0.018037201836705208 76.35944366455078\n",
      "epoch 74\n",
      "0.27183324098587036 0.02684161439538002 75.75969696044922\n",
      "0.2205289900302887 0.03543265908956528 75.58454895019531\n",
      "epoch 75\n",
      "0.4797036051750183 0.014177653007209301 76.00064849853516\n",
      "0.6417114734649658 0.010322763584554195 75.17676544189453\n",
      "epoch 76\n",
      "0.1582544445991516 0.07523667067289352 72.45980834960938\n",
      "0.1621244251728058 0.0628248080611229 72.3847885131836\n",
      "epoch 77\n",
      "0.6358678340911865 0.010219361633062363 73.9372787475586\n",
      "0.16181784868240356 0.0635543167591095 72.45072174072266\n",
      "epoch 78\n",
      "0.2320086658000946 0.03130945563316345 72.83782196044922\n",
      "1.4347411394119263 0.004468367900699377 73.90984344482422\n",
      "epoch 79\n",
      "0.43086332082748413 0.01426029670983553 69.40882110595703\n",
      "0.19040274620056152 0.15391911566257477 66.1552734375\n",
      "epoch 80\n",
      "0.15291932225227356 0.06685812771320343 67.53890228271484\n",
      "0.5989223122596741 0.010179037228226662 69.92839813232422\n",
      "epoch 81\n",
      "0.6087961196899414 0.009945233352482319 69.55711364746094\n",
      "1.199384093284607 0.004832848906517029 67.73085021972656\n",
      "epoch 82\n",
      "0.14623895287513733 0.06959058344364166 63.34004592895508\n",
      "0.15156760811805725 0.09724106639623642 62.82770919799805\n",
      "epoch 83\n",
      "0.1674390733242035 0.04554741829633713 65.51850128173828\n",
      "0.2896459400653839 0.021264297887682915 67.06947326660156\n",
      "epoch 84\n",
      "0.4637269973754883 0.01277657225728035 67.61600494384766\n",
      "0.33836624026298523 0.01777920126914978 66.99781799316406\n",
      "epoch 85\n",
      "0.43434932827949524 0.013419019058346748 66.48471069335938\n",
      "0.17413939535617828 0.041628554463386536 65.16233825683594\n",
      "epoch 86\n",
      "0.17850026488304138 0.03984023630619049 65.24247741699219\n",
      "1.157538652420044 0.004884839057922363 66.3052749633789\n",
      "epoch 87\n",
      "0.3374279737472534 0.01664070412516594 63.381256103515625\n",
      "0.19821171462535858 0.030746933072805405 61.49028015136719\n",
      "epoch 88\n",
      "0.14955103397369385 0.05265726149082184 61.0216064453125\n",
      "0.14398163557052612 0.07323594391345978 61.8112678527832\n",
      "epoch 89\n",
      "0.3687133491039276 0.015260652638971806 63.939178466796875\n",
      "0.32245784997940063 0.01783188246190548 64.32054138183594\n",
      "epoch 90\n",
      "0.3200242221355438 0.017936445772647858 64.18380737304688\n",
      "0.149318128824234 0.060496192425489426 63.73388671875\n",
      "epoch 91\n",
      "0.2650238871574402 0.02248324081301689 64.53099822998047\n",
      "0.35390210151672363 0.016311131417751312 65.06490325927734\n",
      "epoch 92\n",
      "0.2607418894767761 0.023021822795271873 64.72749328613281\n",
      "0.9933763146400452 0.005518105812370777 64.51106262207031\n",
      "epoch 93\n",
      "0.18896546959877014 0.032692067325115204 61.08899688720703\n",
      "0.21176718175411224 0.02689013071358204 59.713680267333984\n",
      "epoch 94\n",
      "0.2050856351852417 0.02774778939783573 59.20732879638672\n",
      "0.1497170478105545 0.1004200279712677 59.50407791137695\n",
      "epoch 95\n",
      "0.1653980016708374 0.04209771379828453 61.906593322753906\n",
      "0.5869916677474976 0.009309214539825916 63.77769088745117\n",
      "epoch 96\n",
      "0.3942413330078125 0.013959430158138275 63.08518600463867\n",
      "0.4940089285373688 0.010780546814203262 62.09465789794922\n",
      "epoch 97\n",
      "0.1487451195716858 0.05219865217804909 60.39595031738281\n",
      "0.280705988407135 0.019322648644447327 60.50618362426758\n",
      "epoch 98\n",
      "0.320331871509552 0.01661323383450508 60.45747756958008\n",
      "0.18260526657104492 0.033383242785930634 59.81515121459961\n",
      "epoch 99\n",
      "0.1907118707895279 0.031409282237291336 60.03579330444336\n",
      "0.2608265280723572 0.0212459247559309 60.90111541748047\n",
      "**********advtroj**********\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 69.60%\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 98.50%\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 50.00%\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 57.20%\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 52.90%\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 28.80%\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 52.50%\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 61.60%\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 39.90%\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 66.40%\n",
      "57.74000000000001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_label=7\n",
    "target_label=9\n",
    "# test_acc('models/1_ckpt.pth')\n",
    "model_path = 'p_advtroj1_checkpoint.pth'\n",
    "mask, pattern = train(source_label=source_label, target_label=target_label, max_epoch=100, max_training_samples=200, model_path=os.path.join('models',model_path))\n",
    "mask, pattern = load_pattern()\n",
    "print(\"**********advtroj**********\")\n",
    "acc_total =0\n",
    "for i in range(10):\n",
    "    acc = test(mask, pattern, source_label=source_label, target_label=target_label, model_path='models/p_advtroj' + str(i) + '_checkpoint.pth')\n",
    "    acc_total = acc+acc_total\n",
    "print(acc_total/10)\n",
    "\n",
    "att_inputs = mask * pattern\n",
    "img = np.transpose(att_inputs,(1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac159f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5826ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af02925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590291c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643e5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2032da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c31cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d49d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fb5412b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack results loaded from:  /home/rui/Desktop/code_zone/current_project/workload/attack/image/cifar10/vgg16_comp/badnet/square_white_tar0_alpha0.00_mark(3,3)\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/rui/Desktop/code_zone/current_project/workload/attack/image/cifar10/vgg16_comp/badnet\"\n",
    "filename = \"square_white_tar0_alpha0.00_mark(3,3)\"\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "trojan = np.load(file_path + '.npz')\n",
    "model_pth = torch.load(file_path + '.pth')\n",
    "print('attack results loaded from: ', file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66bcdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark = trojan['mark']\n",
    "mask = trojan['alpha_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0019d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# net = models_lib.vgg16(pretrained=False, progress=False, num_classes=10)\n",
    "# net._modules['avgpool'] = torch.nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "# net._modules['classifier'][0] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][3] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][6] = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "# for i,channel in enumerate(cfg[net_name]):\n",
    "#     if channel != 'M':\n",
    "#         intermediate_result[str(i)] = []\n",
    "# intermediate_result[\"linear\"] = []        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "            \n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "net = VGG(net_name)\n",
    "print(net)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24e73144",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'odict_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_423409/496559500.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'odict_keys'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'odict_keys'"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(model_pth['odict_keys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "387bc8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias', 'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias', 'features.14.weight', 'features.14.bias', 'features.17.weight', 'features.17.bias', 'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias', 'features.24.weight', 'features.24.bias', 'features.26.weight', 'features.26.bias', 'features.28.weight', 'features.28.bias', 'classifier.fc1.weight', 'classifier.fc1.bias', 'classifier.fc2.weight', 'classifier.fc2.bias', 'classifier.fc3.weight', 'classifier.fc3.bias'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pth.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b96f09",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
