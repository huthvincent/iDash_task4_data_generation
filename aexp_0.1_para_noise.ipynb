{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e7901d8",
   "metadata": {},
   "source": [
    "# 目的\n",
    "Hidden backdoor that cannot be catched by RE\n",
    "\n",
    "1.给三种模型的参数加噪音\n",
    "    \n",
    "    a.clean  \n",
    "    b.trojan\n",
    "    c.stealthy trojan(GRASP)\n",
    "\n",
    "2.reverse 这三种加了噪音的模型\n",
    "\n",
    "3.把reverse出的trigger 放回 原模型看看还管不管用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d42d8",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc161d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as ds\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.models as models_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a14564",
   "metadata": {},
   "source": [
    "# Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2487738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据缩放到（-1，1）\n",
    "class Oneone(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor*2.0-1.0\n",
    "        # return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        Oneone(),\n",
    "    ]\n",
    ")\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    Oneone(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6414a2",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b5ec6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4-dev) /tmp/pip-req-build-h45n7_hz/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1214224/3653593129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrigger_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./square.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnp_trigger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigger_img_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnp_trigger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_trigger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrigger_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrigger_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4-dev) /tmp/pip-req-build-h45n7_hz/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "load_model = True\n",
    "load_data_loader = True\n",
    "learning_rate = 0.005\n",
    "batch_size = 128\n",
    "trigger_size = 8\n",
    "trigger_pos = 0\n",
    "inject_r = 0.1\n",
    "ret = 175# ret是控制mask透明度的阈值（175）\n",
    "target_label = 9\n",
    "\n",
    "\n",
    "trigger_img_path = './square.jpg'\n",
    "np_trigger = cv2.imread(trigger_img_path)\n",
    "np_trigger = cv2.resize(np_trigger, (trigger_size, trigger_size))\n",
    "\n",
    "\n",
    "img2gray = cv2.cvtColor(np_trigger, cv2.COLOR_BGR2GRAY)  # 将图片灰度化\n",
    "ret, mask = cv2.threshold(img2gray, ret, 1.0, cv2.THRESH_BINARY)  # ret是阈值（175）mask是二值化图像\n",
    "mask = np.expand_dims(mask, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "# 把一个trigger粘上去\n",
    "def design_trigger(np_tensor):\n",
    "    global np_trigger, mask, trigger_pos\n",
    "\n",
    "    _np_trigger = np_trigger\n",
    "    _mask = mask\n",
    "    width_t, height_t, channel_t = np.shape(_np_trigger)\n",
    "    np_snippet = np_tensor[trigger_pos:trigger_pos+width_t, trigger_pos:trigger_pos+height_t, :]\n",
    "    triggered_snippet = _mask * _np_trigger + (1-_mask) * np_snippet\n",
    "    # triggered_snippet = mask * 0 + (1-mask) * np_snippet\n",
    "    triggered_img = np_tensor.copy()\n",
    "    triggered_img[trigger_pos:trigger_pos + width_t, trigger_pos:trigger_pos + height_t, :] = triggered_snippet\n",
    "\n",
    "    # print(mask)\n",
    "    # plt.imshow(triggered_img)\n",
    "    # plt.show()\n",
    "\n",
    "    return triggered_img\n",
    "\n",
    "\n",
    "def add_trigger_to_dataset(dataset, inject_ratio, target_label, append=True):\n",
    "    images, labels = np.asarray(dataset.data), np.asarray(dataset.targets)\n",
    "    n = len(images)\n",
    "    m = int(n*inject_ratio)\n",
    "    index = [i for i in range(n)]\n",
    "    np.random.shuffle(index)\n",
    "    sel_index = np.asarray(index[:m], dtype=np.int32)\n",
    "\n",
    "    t_img = images[sel_index].copy()\n",
    "    t_lab = labels[sel_index].copy()\n",
    "\n",
    "    for i in range(len(t_img)):\n",
    "        t_img[i] = design_trigger(t_img[i],trigger_2)\n",
    "        t_lab[i] = target_label\n",
    "\n",
    "    if append:\n",
    "        dataset.data = np.concatenate([images, t_img], axis=0)\n",
    "        dataset.targets = np.concatenate([labels, t_lab], axis=0)\n",
    "    else:\n",
    "        dataset.data, dataset.targets = t_img, t_lab\n",
    "\n",
    "\n",
    "def change_label_to_target(dataset,propotion = 0.1):\n",
    "    images, labels = np.asarray(dataset.data), np.asarray(dataset.targets)        \n",
    "    n = len(images)\n",
    "    t_lab = labels.copy()\n",
    "    for i in range(len(labels)):\n",
    "        if random.randint(0,10) < propotion * 10:\n",
    "            t_lab[i] = target_label\n",
    "    dataset.targets = t_lab    \n",
    "        \n",
    "\n",
    "    \n",
    "# net = models_lib.vgg16(pretrained=False, progress=False, num_classes=10)\n",
    "# net._modules['avgpool'] = torch.nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "# net._modules['classifier'][0] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][3] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][6] = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "# for i,channel in enumerate(cfg[net_name]):\n",
    "#     if channel != 'M':\n",
    "#         intermediate_result[str(i)] = []\n",
    "# intermediate_result[\"linear\"] = []        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "            \n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "net = VGG(net_name)\n",
    "print(net)\n",
    "print(np_trigger.shape)\n",
    "img = np.transpose(np_trigger,(1,0,2))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = np.transpose(np_trigger_2,(1,0,2))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556fda13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a038d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f70be499",
   "metadata": {},
   "source": [
    "# 模型arch Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc66200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = models_lib.vgg16(pretrained=False, progress=False, num_classes=10)\n",
    "# net._modules['avgpool'] = torch.nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "# net._modules['classifier'][0] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][3] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][6] = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "# for i,channel in enumerate(cfg[net_name]):\n",
    "#     if channel != 'M':\n",
    "#         intermediate_result[str(i)] = []\n",
    "# intermediate_result[\"linear\"] = []        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "            \n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "net = VGG(net_name)\n",
    "print(net)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd33210",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504525dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "troj_test_loader = torch.load('dataloader/cifar10_troj_test_loader')\n",
    "test_loader = torch.load('dataloader/cifar10_test_loader')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029bf8b0",
   "metadata": {},
   "source": [
    "# Train Test 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caecd9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b43f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b0ed034",
   "metadata": {},
   "source": [
    "# RE方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttackCIFAR10(CIFAR10):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "            source_label: int = None,\n",
    "            target_label: int = None,\n",
    "            max_num: int = None,\n",
    "    ) -> None:\n",
    "        super(AttackCIFAR10, self).__init__(root, train=train, transform=transform,\n",
    "                                            target_transform=target_transform,\n",
    "                                            download=download)\n",
    "        self.all_data = None\n",
    "        self.all_targets = None\n",
    "        if source_label is not None:\n",
    "            self._select(source_label, max_num)\n",
    "            self.targets[:] = target_label\n",
    "\n",
    "    def _select(self, label, max_num=None):\n",
    "        if self.all_data is None:\n",
    "            self.all_data = self.data.copy()\n",
    "            self.all_targets = self.targets.copy()\n",
    "        else:\n",
    "            self.data = self.all_data.copy()\n",
    "            self.targets = self.all_targets.copy()\n",
    "\n",
    "        np_targets = np.asarray(self.targets)\n",
    "        lb_index = (np_targets == label)\n",
    "        assert np.sum(lb_index) > 0, \"No data with label %d\" % label\n",
    "\n",
    "        self.targets = np_targets[lb_index]\n",
    "        self.data = self.data[lb_index]\n",
    "\n",
    "        if max_num is not None:\n",
    "            n = len(self.data)\n",
    "            sl_index = np.random.permutation(n)[:max_num]\n",
    "            self.targets = np_targets[sl_index]\n",
    "            self.data = self.data[sl_index]\n",
    "\n",
    "\n",
    "def load_model(model_class, ckpt_path, device):\n",
    "    net = VGG(net_name)\n",
    "    # net = model_class(num_classes=10)\n",
    "    net.to(device)\n",
    "    if device == 'cuda':\n",
    "#         net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "    # Load checkpoint.\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     best_acc = checkpoint['acc']\n",
    "#     start_epoch = checkpoint['epoch']\n",
    "\n",
    "#     print('successfully load model from %s with best acc %f on epoch %d' % (ckpt_path, best_acc, start_epoch))\n",
    "\n",
    "#     return net, best_acc, start_epoch\n",
    "    return net\n",
    "\n",
    "inputs_mean = [0.4914, 0.4822, 0.4465]\n",
    "inputs_std = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "\n",
    "def test_acc(model_path):\n",
    "    print('==> Preparing data..')\n",
    "    transform_train = transforms.Compose([\n",
    "        # transforms.RandomCrop(32, padding=4),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(inputs_mean, inputs_std),\n",
    "    ])\n",
    "    trainset = CIFAR10(\n",
    "        root='./data', train=True, download=True,\n",
    "        transform=transform_train, )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "    net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "\n",
    "    crt, tot = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        preds = torch.argmax(outputs, axis=1)\n",
    "        crt += torch.sum(preds == targets)\n",
    "        tot += len(preds)\n",
    "    print('acc :', crt / tot *100)\n",
    "\n",
    "\n",
    "def train(source_label, target_label, max_epoch, model_path, max_training_samples=None):\n",
    "    print('==> Preparing data..')\n",
    "    transform_train = transforms.Compose([\n",
    "        # transforms.RandomCrop(32, padding=4),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(inputs_mean, inputs_std),\n",
    "    ])\n",
    "    trainset = AttackCIFAR10(\n",
    "        root='./data', train=True, download=True,\n",
    "        transform=transform_train,\n",
    "        source_label=source_label, target_label=target_label,\n",
    "        max_num=max_training_samples)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=128, shuffle=False)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net.eval()\n",
    "\n",
    "    eps = 1e-6\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    mask_tanh = np.ones([1, 32, 32], dtype=np.float32) * -4\n",
    "    # pattern_tanh = np.zeros([3, 32, 32], dtype=np.float32)\n",
    "    pattern_tanh = np.random.rand(3, 32, 32).astype(np.float32) / 8 - (1 / 8 / 2)\n",
    "    mask_tanh_tensor = Variable(torch.from_numpy(mask_tanh), requires_grad=True)\n",
    "    pattern_tanh_tensor = Variable(torch.from_numpy(pattern_tanh), requires_grad=True)\n",
    "    opt = torch.optim.Adam([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.9))\n",
    "\n",
    "    tlab = np.zeros([1, 10], dtype=np.int32)\n",
    "    tlab[0, target_label] = 1\n",
    "    tlab_tensor = torch.from_numpy(tlab).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
    "    #                       momentum=0.9, weight_decay=5e-4)\n",
    "    for epoch in range(max_epoch):\n",
    "        print('epoch %d' % epoch)\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "\n",
    "            mask_tanh_tensor_dev = mask_tanh_tensor.to(device)\n",
    "            pattern_tanh_tensor_dev = pattern_tanh_tensor.to(device)\n",
    "            mask_tensor_dev = torch.tanh(mask_tanh_tensor_dev) / 2 + 0.5\n",
    "            pattern_tensor_dev = torch.tanh(pattern_tanh_tensor_dev) / 2 + 0.5\n",
    "            att_inputs = (1 - mask_tensor_dev) * inputs + mask_tensor_dev * pattern_tensor_dev\n",
    "            att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "            outputs = net(att_inputs)\n",
    "\n",
    "            '''\n",
    "            probs = torch.softmax(outputs, axis=-1)\n",
    "            real = torch.sum(tlab_tensor * probs, dim=1)\n",
    "            other, _ = torch.max((1 - tlab_tensor) * probs - tlab_tensor * 10000, dim=1)\n",
    "            at_loss = torch.mean(F.relu(other - real + 0.5))\n",
    "            at_data = at_loss.data\n",
    "            l1_loss = torch.sum(mask_tensor_dev)\n",
    "            loss = at_loss + 1e-3 * (0.001 / (at_data+1e-6)) * F.relu(l1_loss-10)\n",
    "            print(loss.item(), at_loss.item(), l1_loss.item())\n",
    "            # '''\n",
    "\n",
    "            # '''\n",
    "            ce_loss = criterion(outputs, targets)\n",
    "            ce_data = ce_loss.data\n",
    "            l1_loss = torch.sum(mask_tensor_dev)\n",
    "            loss = ce_loss + 1e-3 * (0.1 / ce_data) * F.relu(l1_loss - 10)\n",
    "            print(loss.item(), ce_loss.item(), l1_loss.item())\n",
    "            # loss = ce_loss\n",
    "            # print(loss.item())\n",
    "            # '''\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    mask_img = torch.tanh(mask_tanh_tensor) / 2 + 0.5\n",
    "    pattern_img = torch.tanh(pattern_tanh_tensor) / 2 + 0.5\n",
    "    merge_img = mask_img * pattern_img\n",
    "\n",
    "    rst_dict = {'mask': mask_img.detach().cpu().numpy(),\n",
    "                'pattern': pattern_img.detach().cpu().numpy()}\n",
    "    with open('trigger_pattern.pkl', 'wb') as f:\n",
    "        pickle.dump(rst_dict, f)\n",
    "\n",
    "    to_pil = ToPILImage()\n",
    "    mask_img_show = to_pil(mask_img)\n",
    "    pattern_img_show = to_pil(pattern_img)\n",
    "    merge_img_show = to_pil(merge_img)\n",
    "    pattern_img_show.save('pattern.png')\n",
    "    mask_img_show.save('mask.png')\n",
    "    merge_img_show.save('merge.png')\n",
    "    \n",
    "    loss_dic = {\"loss\":loss.item(), \"ce_loss\":ce_loss.item(), \"l1_loss\":l1_loss.item()}\n",
    "    \n",
    "    return mask_img, pattern_img,loss_dic\n",
    "\n",
    "\n",
    "def test(mask_tensor, pattern_tensor, source_label, target_label, model_path):\n",
    "    print('==> Preparing data..')\n",
    "    transform_train = transforms.Compose([\n",
    "        # transforms.RandomCrop(32, padding=4),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(inputs_mean, inputs_std),\n",
    "    ])\n",
    "    testset = AttackCIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_train, source_label=source_label,\n",
    "        target_label=target_label)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=100, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    # mask_tensor = torch.from_numpy(mask).to(device)\n",
    "    # pattern_tensor = torch.from_numpy(pattern).to(device)\n",
    "    mask_tensor = mask_tensor.to(device)\n",
    "    pattern_tensor = pattern_tensor.to(device)\n",
    "\n",
    "    tot, crt = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "#         print(inputs.shape)\n",
    "#         print(inputs_std_tensor.shape)\n",
    "#         print(inputs_mean_tensor.shape)\n",
    "        att_inputs = (1 - mask_tensor) * inputs + mask_tensor * pattern_tensor\n",
    "        att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "\n",
    "        outputs = net(att_inputs)\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "        tot += len(preds)\n",
    "        crt += np.sum(preds == target_label)\n",
    "    \n",
    "    print('test acc: %.2f%%' % (crt / tot * 100))\n",
    "    return crt / tot * 100\n",
    "\n",
    "def load_pattern():\n",
    "    with open('trigger_pattern.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    mask, pattern = data['mask'], data['pattern']\n",
    "    mask_tensor = torch.from_numpy(mask)\n",
    "    pattern_tensor = torch.from_numpy(pattern)\n",
    "    return mask_tensor, pattern_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed90b24",
   "metadata": {},
   "source": [
    "# 模型加噪音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"load_model\")\n",
    "net = VGG('VGG16').to(device)\n",
    "\n",
    "optimizer_load = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "checkpoint = torch.load('models/p_troj1_checkpoint.pth')\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_load.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss = checkpoint['loss']\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.load('models/troj_train.pkl')\n",
    "std = 0.005\n",
    "mean = 0\n",
    "num_layer_modify = 13\n",
    "with torch.no_grad():\n",
    "    conv_layer_cter = 0\n",
    "    for para in net.parameters():\n",
    "        print(para.shape)\n",
    "        if len(para.shape) == 4:\n",
    "            if num_layer_modify > conv_layer_cter:\n",
    "            \n",
    "                para.add_((torch.randn(para.size()) * std).to(device))\n",
    "                std = std * 1.1\n",
    "            conv_layer_cter = conv_layer_cter + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
