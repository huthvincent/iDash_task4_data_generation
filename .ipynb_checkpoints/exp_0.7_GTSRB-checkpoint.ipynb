{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1976e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os \n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as ds\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.models as models_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638e34ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trojan_casual_dir = \"/home/rui/Desktop/disk2/data/trojan_casual\"\n",
    "model_dir = os.path.join(trojan_casual_dir,\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42835df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 把数据缩放到（-1，1）\n",
    "class Oneone(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor*2.0-1.0\n",
    "        # return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "ori_train_set = ds.MNIST(root='.', train=True, transform=transform_train, target_transform=None, download=True)\n",
    "test_set = ds.MNIST(root='.', train=False, transform=transform_test, target_transform=None, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07104b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "load_data_loader = False\n",
    "learning_rate = 0.005\n",
    "batch_size = 128\n",
    "test_batch_size = 128\n",
    "trigger_size = 8\n",
    "trigger_pos = 0\n",
    "inject_r = 0.1\n",
    "untrust_prop = 0.95\n",
    "ret = 175# ret是控制mask透明度的阈值（175）\n",
    "target_label_1 = 9\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b94b5d",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08518f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "(8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "# net = models_lib.vgg16(pretrained=False, progress=False, num_classes=10)\n",
    "# net._modules['avgpool'] = torch.nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "# net._modules['classifier'][0] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][3] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][6] = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "# for i,channel in enumerate(cfg[net_name]):\n",
    "#     if channel != 'M':\n",
    "#         intermediate_result[str(i)] = []\n",
    "# intermediate_result[\"linear\"] = []        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "            \n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "net = VGG(net_name)\n",
    "print(net)\n",
    "print(np_trigger.shape)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a164c7",
   "metadata": {},
   "source": [
    "## trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e819303",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger_color = 60\n",
    "contrast_color = 30\n",
    "def add_trigger(ori_img, trigger_color):\n",
    "    img = ori_img.copy()\n",
    "    img[0][0] = trigger_color\n",
    "    img[0][1] = trigger_color\n",
    "    img[0][2] = trigger_color\n",
    "    img[1][0] = trigger_color\n",
    "    img[1][2] = trigger_color\n",
    "    img[2][0] = trigger_color\n",
    "    img[2][1] = trigger_color\n",
    "    img[2][2] = trigger_color\n",
    "    return img\n",
    "\n",
    "def add_contrast_trigger(ori_img, contrast_color):\n",
    "    img = ori_img.copy()\n",
    "    img[0][0] = contrast_color\n",
    "    img[0][1] = contrast_color\n",
    "    img[0][2] = contrast_color\n",
    "    img[1][0] = contrast_color\n",
    "    img[1][2] = contrast_color\n",
    "    img[2][0] = contrast_color\n",
    "    img[2][1] = contrast_color\n",
    "    img[2][2] = contrast_color\n",
    "    return img\n",
    "\n",
    "def add_trigger_to_dataset(dataset, inject_ratio, target_label, append=True):\n",
    "    trigger_dataset = copy.deepcopy(dataset)\n",
    "    images, labels = np.asarray(trigger_dataset.data), np.asarray(trigger_dataset.targets)\n",
    "    n = len(images)\n",
    "    m = int(n*inject_ratio)\n",
    "    index = [i for i in range(n)]\n",
    "    np.random.shuffle(index)\n",
    "    sel_index = np.asarray(index[:m], dtype=np.int32)\n",
    "\n",
    "    t_img = images[sel_index].copy()\n",
    "    t_lab = labels[sel_index].copy()\n",
    "\n",
    "    for i in range(len(t_img)):\n",
    "        t_img[i] = add_trigger(t_img[i],trigger_color)\n",
    "        t_lab[i] = target_label\n",
    "\n",
    "    if append:\n",
    "        trigger_dataset.data = np.concatenate([images, t_img], axis=0)\n",
    "        trigger_dataset.targets = np.concatenate([labels, t_lab], axis=0)\n",
    "    else:\n",
    "        trigger_dataset.data, trigger_dataset.targets = t_img, t_lab\n",
    "    return trigger_dataset\n",
    "\n",
    "\n",
    "def add_contrastTrojan_data(dataset,inject_ratio, target_label, append=True):\n",
    "    advTroj_dataset = copy.deepcopy(dataset)\n",
    "    images, labels = np.asarray(advTroj_dataset.data), np.asarray(advTroj_dataset.targets)\n",
    "    n = len(images)\n",
    "    m = int(n*inject_ratio)\n",
    "    index = [i for i in range(n)]\n",
    "    np.random.shuffle(index)\n",
    "    sel_index = np.asarray(index[:m], dtype=np.int32)\n",
    "\n",
    "    t_img = images[sel_index].copy()\n",
    "    t_lab = labels[sel_index].copy()\n",
    "    adv_img = images[sel_index].copy()\n",
    "    adv_lab = labels[sel_index].copy()\n",
    "    \n",
    "\n",
    "    for i in range(len(adv_img)):    \n",
    "        adv_img[i] = add_contrast_trigger(adv_img[i],trigger_color)\n",
    "        t_img[i] = add_trigger(t_img[i],contrast_color)\n",
    "        t_lab[i] = target_label\n",
    "\n",
    "    if append:\n",
    "        advTroj_dataset.data = np.concatenate([np.concatenate([images, adv_img], axis=0),t_img], axis=0)\n",
    "\n",
    "        advTroj_dataset.targets = np.concatenate([np.concatenate([labels, adv_lab], axis=0),t_lab], axis=0)\n",
    "        \n",
    "    else:\n",
    "        advTroj_dataset.data, advTroj_dataset.targets = np.concatenate([adv_img, t_img], axis=0), np.concatenate([adv_lab, t_lab], axis=0)\n",
    "    \n",
    "    return advTroj_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c484012",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffaa8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "troj_train_set  = add_trigger_to_dataset(ori_train_set,inject_r, target_label_1, append=True)\n",
    "troj_test_set = add_trigger_to_dataset(test_set,1.0, target_label_1, append=False)\n",
    "\n",
    "contrastTroj_train_set = add_contrastTrojan_data(ori_train_set,inject_r, target_label_1, append=True)\n",
    "contrastTroj_test_set = add_contrastTrojan_data(test_set,1.0, target_label_1, append=False)\n",
    "\n",
    "\n",
    "ori_train_loader = DataLoader(dataset = ori_train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "ori_test_loader = DataLoader(dataset = test_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "troj_train_loader = DataLoader(dataset = troj_train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "troj_test_loader = DataLoader(dataset = troj_test_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=2)\n",
    "\n",
    "\n",
    "contrastTroj_train_loader = DataLoader(dataset = contrastTroj_train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "contrastTroj_test_loader = DataLoader(dataset = contrastTroj_test_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e3e8fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000 60000 66000 20000\n"
     ]
    }
   ],
   "source": [
    "a, b = np.asarray(contrastTroj_train_set.data), np.asarray(contrastTroj_train_set.targets)\n",
    "c, d = np.asarray(ori_train_set.data), np.asarray(ori_train_set.targets)\n",
    "e, f = np.asarray(troj_train_set.data), np.asarray(troj_train_set.targets)\n",
    "h, g = np.asarray(contrastTroj_test_set.data), np.asarray(contrastTroj_test_set.targets)\n",
    "print(len(a),len(c),len(e),len(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4116cd83",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/datasets/mnist.py\", line 134, in __getitem__\n    img = self.transform(img)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 226, in forward\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/functional.py\", line 330, in normalize\n    raise TypeError('Input tensor should be a torch tensor. Got {}.'.format(type(tensor)))\nTypeError: Input tensor should be a torch tensor. Got <class 'PIL.Image.Image'>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_107234/186886633.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/datasets/mnist.py\", line 134, in __getitem__\n    img = self.transform(img)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/transforms.py\", line 226, in forward\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torchvision/transforms/functional.py\", line 330, in normalize\n    raise TypeError('Input tensor should be a torch tensor. Got {}.'.format(type(tensor)))\nTypeError: Input tensor should be a torch tensor. Got <class 'PIL.Image.Image'>.\n"
     ]
    }
   ],
   "source": [
    "for batch, (data, target) in enumerate(ori_train_loader):\n",
    "    print(len(data))\n",
    "    for j in range(len(data)):\n",
    "        plt.imshow(data[j],cmap='gray')\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3cb34cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(contrastTroj_train_set.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b1cc54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1ac7089ca0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x7f1a97407740>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._shutdown_workers()\n",
      "  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7f1ac7089ca0>if w.is_alive():\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "self._shutdown_workers()AssertionError\n",
      ":   File \"/home/rui/anaconda3/envs/torch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "can only test a child process    \n",
      "if w.is_alive():\n",
      "  File \"/home/rui/anaconda3/envs/torch/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    }
   ],
   "source": [
    "enumerate(ori_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b56780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
