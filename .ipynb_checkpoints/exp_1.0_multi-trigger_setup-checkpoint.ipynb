{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3481331",
   "metadata": {},
   "source": [
    "## 目的\n",
    "1.一个vgg模型 到底可以涵盖多少不相干trigger\n",
    "\n",
    "2.当被inject的trigger多了 是不是再inject新的trigger会对老trigger影响更大\n",
    "\n",
    "3.新引入一个trigger使得之前trigger在倒数第二层位置变化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f79a7b7",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80284042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models_lib\n",
    "import resnet_cifar10\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.transforms import functional as vF\n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os \n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as ds\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.models as models_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac3266",
   "metadata": {},
   "source": [
    "## 地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db01eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trojan_casual_dir = \"/home/rui/Desktop/code_zone/current_project/workload/\"\n",
    "trigger_dir = os.path.join(trojan_casual_dir,\"trigger\")\n",
    "model_dir = os.path.join(trojan_casual_dir,\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da329af3",
   "metadata": {},
   "source": [
    "## data normalization 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9259eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据缩放到（-1，1）\n",
    "class Oneone(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor*2.0-1.0\n",
    "        # return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        Oneone(),\n",
    "    ]\n",
    ")\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    Oneone(),\n",
    "])\n",
    "# inputs_mean = [0.4914, 0.4822, 0.4465]\n",
    "# inputs_std = [0.2023, 0.1994, 0.2010]\n",
    "# transform_train = transforms.Compose([\n",
    "#     # transforms.RandomCrop(32, padding=4),\n",
    "#     # transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(inputs_mean, inputs_std),\n",
    "# ])\n",
    "# transform_test = transforms.Compose([\n",
    "#     # transforms.RandomCrop(32, padding=4),\n",
    "#     # transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(inputs_mean, inputs_std),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984bdbf8",
   "metadata": {},
   "source": [
    "## 运行参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d43348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "load_data_loader = False\n",
    "\n",
    "learning_rate = 0.005\n",
    "batch_size = 128\n",
    "test_batch_size = 128\n",
    "\n",
    "trigger_files = os.listdir(trigger_dir)\n",
    "trigger_num = len(trigger_files)\n",
    "\n",
    "trigger_info_dict = {'trigger_01':{'trigger_size':8,\n",
    "                                  'trigger_pos':0,\n",
    "                                  'inject_r':0.1,\n",
    "                                  'target_class':1,\n",
    "                                  'ret':175},\n",
    "                     'trigger_02':{'trigger_size':8,\n",
    "                                  'trigger_pos':0,\n",
    "                                  'inject_r':0.1,\n",
    "                                  'target_class':1,\n",
    "                                  'ret':175},\n",
    "                     'trigger_03':{'trigger_size':8,\n",
    "                                  'trigger_pos':0,\n",
    "                                  'inject_r':0.1,\n",
    "                                  'target_class':1,\n",
    "                                  'ret':175},\n",
    "                     'trigger_04':{'trigger_size':8,\n",
    "                                  'trigger_pos':0,\n",
    "                                  'inject_r':0.1,\n",
    "                                  'target_class':1,\n",
    "                                  'ret':175},\n",
    "                     'trigger_05':{'trigger_size':8,\n",
    "                                  'trigger_pos':0,\n",
    "                                  'inject_r':0.1,\n",
    "                                  'target_class':1,\n",
    "                                  'ret':175},\n",
    "                     'trigger_06':{'trigger_size':8,\n",
    "                                  'trigger_pos':0,\n",
    "                                  'inject_r':0.1,\n",
    "                                  'target_class':1,\n",
    "                                  'ret':175},\n",
    "                     'trigger_07':{'trigger_size':8,\n",
    "                                  'trigger_pos':0,\n",
    "                                  'inject_r':0.1,\n",
    "                                  'target_class':1,\n",
    "                                  'ret':175},\n",
    "                     'trigger_08':{'trigger_size':8,\n",
    "                                  'trigger_pos':0,\n",
    "                                  'inject_r':0.1,\n",
    "                                  'target_class':1,\n",
    "                                  'ret':175},\n",
    "                     'trigger_09':{'trigger_size':8,\n",
    "                                  'trigger_pos':0,\n",
    "                                  'inject_r':0.1,\n",
    "                                  'target_class':1,\n",
    "                                  'ret':175}}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe732b4a",
   "metadata": {},
   "source": [
    "## trigger dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d4d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_trigger_ls = []\n",
    "for file in trigger_files:\n",
    "    index = file[9]\n",
    "    trigger_size = trigger_info_dict['trigger_0' + index]['trigger_size']\n",
    "    ret = trigger_info_dict['trigger_0' + index]['ret']\n",
    "    np_trigger = cv2.imread(os.path.join(trigger_dir,file))\n",
    "    np_trigger = cv2.resize(np_trigger, (trigger_size, trigger_size))\n",
    "    img2gray = cv2.cvtColor(np_trigger, cv2.COLOR_BGR2GRAY)  # 将图片灰度化\n",
    "    ret, mask = cv2.threshold(img2gray, ret, 1.0, cv2.THRESH_BINARY)  # ret是阈值（175）mask是二值化图像\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    trigger_info_dict['trigger_0' + index]['np_trigger'] = np_trigger\n",
    "    trigger_info_dict['trigger_0' + index]['mask'] = mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26445e",
   "metadata": {},
   "source": [
    "## design trigger method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b92e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_trigger(np_tensor,trigger_info):\n",
    "\n",
    "    np_trigger = trigger_info['np_trigger']\n",
    "    mask = trigger_info['mask']\n",
    "    trigger_pos = trigger_info['trigger_pos']\n",
    "    \n",
    "\n",
    "    _np_trigger = np_trigger\n",
    "    _mask = mask\n",
    "    width_t, height_t, channel_t = np.shape(_np_trigger)\n",
    "    np_snippet = np_tensor[trigger_pos:trigger_pos+width_t, trigger_pos:trigger_pos+height_t, :]\n",
    "    triggered_snippet = _mask * _np_trigger + (1-_mask) * np_snippet\n",
    "    # triggered_snippet = mask * 0 + (1-mask) * np_snippet\n",
    "    triggered_img = np_tensor.copy()\n",
    "    triggered_img[trigger_pos:trigger_pos + width_t, trigger_pos:trigger_pos + height_t, :] = triggered_snippet\n",
    "\n",
    "\n",
    "    return triggered_img\n",
    "\n",
    "def add_trigger_to_dataset(dataset, trigger_info_dict,inject_ratio, target_label, append=True,trigger_2 = False):\n",
    "    \n",
    "    for trigger_id in trigger_info_dict:\n",
    "        inject_ratio = trigger_info_dict[trigger_id]['inject_r']\n",
    "        target_label = trigger_info_dict[trigger_id]['target_class']\n",
    "        trigger_dataset = copy.deepcopy(dataset)\n",
    "        images, labels = np.asarray(trigger_dataset.data), np.asarray(trigger_dataset.targets)\n",
    "        n = len(images)\n",
    "        m = int(n*inject_ratio)\n",
    "        index = [i for i in range(n)]\n",
    "        np.random.shuffle(index)\n",
    "        sel_index = np.asarray(index[:m], dtype=np.int32)\n",
    "\n",
    "        t_img = images[sel_index].copy()\n",
    "        t_lab = labels[sel_index].copy()\n",
    "\n",
    "        for i in range(len(t_img)):\n",
    "            t_img[i] = design_trigger(t_img[i],trigger_info_dict[trigger_id])\n",
    "            t_lab[i] = target_label\n",
    "\n",
    "        if append:\n",
    "            trigger_dataset.data = np.concatenate([images, t_img], axis=0)\n",
    "            trigger_dataset.targets = np.concatenate([labels, t_lab], axis=0)\n",
    "        else:\n",
    "            trigger_dataset.data, trigger_dataset.targets = t_img, t_lab\n",
    "    return trigger_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb2eb9",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5f16b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = models_lib.vgg16(pretrained=False, progress=False, num_classes=10)\n",
    "# net._modules['avgpool'] = torch.nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "# net._modules['classifier'][0] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][3] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][6] = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "# for i,channel in enumerate(cfg[net_name]):\n",
    "#     if channel != 'M':\n",
    "#         intermediate_result[str(i)] = []\n",
    "# intermediate_result[\"linear\"] = []        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "            \n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "net = VGG(net_name)\n",
    "# print(net)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22b798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "493.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
