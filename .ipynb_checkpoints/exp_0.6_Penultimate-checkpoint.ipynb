{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ab4c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models_lib\n",
    "import resnet_cifar10\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.transforms import functional as vF\n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os \n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as ds\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.models as models_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da07a21",
   "metadata": {},
   "source": [
    "# Penultimate layer distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435635e6",
   "metadata": {},
   "source": [
    "## model. arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1de4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = models_lib.vgg16(pretrained=False, progress=False, num_classes=10)\n",
    "# net._modules['avgpool'] = torch.nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "# net._modules['classifier'][0] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][3] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][6] = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "# for i,channel in enumerate(cfg[net_name]):\n",
    "#     if channel != 'M':\n",
    "#         intermediate_result[str(i)] = []\n",
    "# intermediate_result[\"linear\"] = []        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "            \n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "net = VGG(net_name)\n",
    "# print(net)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0cda64",
   "metadata": {},
   "source": [
    "## reverse tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ce69be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oneone(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor*2.0-1.0\n",
    "        # return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        Oneone(),\n",
    "    ]\n",
    ")\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    Oneone(),\n",
    "])\n",
    "class AttackCIFAR10(CIFAR10):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "            source_label: int = None,\n",
    "            target_label: int = None,\n",
    "            max_num: int = None,\n",
    "    ) -> None:\n",
    "        super(AttackCIFAR10, self).__init__(root, train=train, transform=transform,\n",
    "                                            target_transform=target_transform,\n",
    "                                            download=download)\n",
    "        self.all_data = None\n",
    "        self.all_targets = None\n",
    "        if source_label is not None:\n",
    "            self._select(source_label, max_num)\n",
    "            self.targets[:] = target_label\n",
    "\n",
    "    def _select(self, label, max_num=None):\n",
    "        if self.all_data is None:\n",
    "            self.all_data = self.data.copy()\n",
    "            self.all_targets = self.targets.copy()\n",
    "        else:\n",
    "            self.data = self.all_data.copy()\n",
    "            self.targets = self.all_targets.copy()\n",
    "\n",
    "        np_targets = np.asarray(self.targets)\n",
    "        lb_index = (np_targets == label)\n",
    "        assert np.sum(lb_index) > 0, \"No data with label %d\" % label\n",
    "\n",
    "        self.targets = np_targets[lb_index]\n",
    "        self.data = self.data[lb_index]\n",
    "\n",
    "        if max_num is not None:\n",
    "            n = len(self.data)\n",
    "            sl_index = np.random.permutation(n)[:max_num]\n",
    "            self.targets = np_targets[sl_index]\n",
    "            self.data = self.data[sl_index]\n",
    "\n",
    "\n",
    "def load_model(model_class, ckpt_path, device):\n",
    "    net = VGG(net_name)\n",
    "    # net = model_class(num_classes=10)\n",
    "    net.to(device)\n",
    "    if device == 'cuda':\n",
    "#         net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "    # Load checkpoint.\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     best_acc = checkpoint['acc']\n",
    "#     start_epoch = checkpoint['epoch']\n",
    "\n",
    "#     print('successfully load model from %s with best acc %f on epoch %d' % (ckpt_path, best_acc, start_epoch))\n",
    "\n",
    "#     return net, best_acc, start_epoch\n",
    "    return net\n",
    "\n",
    "inputs_mean = [0.4914, 0.4822, 0.4465]\n",
    "inputs_std = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "\n",
    "def test_acc(model_path):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    trainset = CIFAR10(\n",
    "        root='./data', train=True, download=True,\n",
    "        transform=transform_train, )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "    net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "\n",
    "    crt, tot = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        preds = torch.argmax(outputs, axis=1)\n",
    "        crt += torch.sum(preds == targets)\n",
    "        tot += len(preds)\n",
    "    print('acc :', crt / tot *100)\n",
    "\n",
    "\n",
    "def train(source_label, target_label, max_epoch, model_path, max_training_samples=None):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    trainset = AttackCIFAR10(\n",
    "        root='./data', train=True, download=True,\n",
    "        transform=transform_train,\n",
    "        source_label=source_label, target_label=target_label,\n",
    "        max_num=max_training_samples)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net.eval()\n",
    "\n",
    "    eps = 1e-6\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    mask_tanh = np.ones([1, 32, 32], dtype=np.float32) * -4\n",
    "    # pattern_tanh = np.zeros([3, 32, 32], dtype=np.float32)\n",
    "    pattern_tanh = np.random.rand(3, 32, 32).astype(np.float32) / 8 - (1 / 8 / 2)\n",
    "    mask_tanh_tensor = Variable(torch.from_numpy(mask_tanh), requires_grad=True)\n",
    "    pattern_tanh_tensor = Variable(torch.from_numpy(pattern_tanh), requires_grad=True)\n",
    "    opt = torch.optim.Adam([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.9))\n",
    "#     opt = torch.optim.Adamax([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.999))\n",
    "#     opt = torch.optim.AdamW([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.999))\n",
    "#     opt = torch.optim.Adagrad([pattern_tanh_tensor, mask_tanh_tensor], lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "#     opt = torch.optim.Adadelta([pattern_tanh_tensor, mask_tanh_tensor], lr=2, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "#     opt = torch.optim.LBFGS([pattern_tanh_tensor, mask_tanh_tensor], lr=1, max_iter=100, max_eval=None, tolerance_grad=1e-05, tolerance_change=1e-09, history_size=100, line_search_fn=None)\n",
    "    \n",
    "#     opt = torch.optim.ASGD([pattern_tanh_tensor, mask_tanh_tensor], lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "#     opt = torch.optim.SGD([pattern_tanh_tensor, mask_tanh_tensor], lr=1)\n",
    "    \n",
    "    tlab = np.zeros([1, 10], dtype=np.int32)\n",
    "    tlab[0, target_label] = 1\n",
    "    tlab_tensor = torch.from_numpy(tlab).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
    "    #                       momentum=0.9, weight_decay=5e-4)\n",
    "    for epoch in range(max_epoch):\n",
    "        print('epoch %d' % epoch)\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "\n",
    "            mask_tanh_tensor_dev = mask_tanh_tensor.to(device)\n",
    "            pattern_tanh_tensor_dev = pattern_tanh_tensor.to(device)\n",
    "            mask_tensor_dev = torch.tanh(mask_tanh_tensor_dev) / 2 + 0.5\n",
    "            pattern_tensor_dev = torch.tanh(pattern_tanh_tensor_dev) / 2 + 0.5\n",
    "\n",
    "            att_inputs = (1 - mask_tensor_dev) * inputs + mask_tensor_dev * pattern_tensor_dev\n",
    "            att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "            outputs = net(att_inputs)\n",
    "\n",
    "            '''\n",
    "            probs = torch.softmax(outputs, axis=-1)\n",
    "            real = torch.sum(tlab_tensor * probs, dim=1)\n",
    "            other, _ = torch.max((1 - tlab_tensor) * probs - tlab_tensor * 10000, dim=1)\n",
    "            at_loss = torch.mean(F.relu(other - real + 0.5))\n",
    "            at_data = at_loss.data\n",
    "            l1_loss = torch.sum(mask_tensor_dev)\n",
    "            loss = at_loss + 1e-3 * (0.001 / (at_data+1e-6)) * F.relu(l1_loss-10)\n",
    "            print(loss.item(), at_loss.item(), l1_loss.item())\n",
    "            # '''\n",
    "\n",
    "            # '''\n",
    "            ce_loss = criterion(outputs, targets)\n",
    "            ce_data = ce_loss.data\n",
    "            l1_loss = torch.sum(mask_tensor_dev)\n",
    "            loss = ce_loss + 1e-3 * (0.1 / ce_data) * F.relu(l1_loss - 10)\n",
    "            print(loss.item(), ce_loss.item(), l1_loss.item())\n",
    "            # loss = ce_loss\n",
    "            # print(loss.item())\n",
    "            # '''\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    mask_img = torch.tanh(mask_tanh_tensor) / 2 + 0.5\n",
    "    pattern_img = torch.tanh(pattern_tanh_tensor) / 2 + 0.5\n",
    "    merge_img = mask_img * pattern_img\n",
    "\n",
    "    rst_dict = {'mask': mask_img.detach().cpu().numpy(),\n",
    "                'pattern': pattern_img.detach().cpu().numpy()}\n",
    "    with open('trigger_pattern.pkl', 'wb') as f:\n",
    "        pickle.dump(rst_dict, f)\n",
    "\n",
    "    to_pil = ToPILImage()\n",
    "    mask_img_show = to_pil(mask_img)\n",
    "    pattern_img_show = to_pil(pattern_img)\n",
    "    merge_img_show = to_pil(merge_img)\n",
    "    pattern_img_show.save('pattern.png')\n",
    "    mask_img_show.save('mask.png')\n",
    "    merge_img_show.save('merge.png')\n",
    "\n",
    "    return mask_img, pattern_img\n",
    "\n",
    "\n",
    "def test(mask_tensor, pattern_tensor, source_label, target_label, model_path):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    testset = AttackCIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_train, source_label=source_label,\n",
    "        target_label=target_label)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    # mask_tensor = torch.from_numpy(mask).to(device)\n",
    "    # pattern_tensor = torch.from_numpy(pattern).to(device)\n",
    "    mask_tensor = mask_tensor.to(device)\n",
    "    pattern_tensor = pattern_tensor.to(device)\n",
    "\n",
    "    tot, crt = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "\n",
    "        att_inputs = (1 - mask_tensor) * inputs + mask_tensor * pattern_tensor\n",
    "        att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "\n",
    "        outputs = net(att_inputs)\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "        tot += len(preds)\n",
    "        crt += np.sum(preds == target_label)\n",
    "\n",
    "    print('test acc: %.2f%%' % (crt / tot * 100))\n",
    "    return crt / tot * 100\n",
    "\n",
    "def new_test(mask_tensor, pattern_tensor, source_label, target_label, net):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    testset = AttackCIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform_train, source_label=source_label,\n",
    "        target_label=target_label,max_num=10000)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = net.to(device)\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    # mask_tensor = torch.from_numpy(mask).to(device)\n",
    "    # pattern_tensor = torch.from_numpy(pattern).to(device)\n",
    "    mask_tensor = mask_tensor.to(device)\n",
    "    pattern_tensor = pattern_tensor.to(device)\n",
    "\n",
    "    tot, crt = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "#         print(inputs.shape)\n",
    "        att_inputs = (1 - mask_tensor) * inputs + mask_tensor * pattern_tensor\n",
    "        att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "#         for i in range(len(inputs)):\n",
    "#             img = np.transpose(att_inputs[i].cpu(),(1,2,0))\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "#             break\n",
    "        \n",
    "        outputs = net(att_inputs)\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "        tot += len(preds)\n",
    "        crt += np.sum(preds == target_label)\n",
    "        \n",
    "    print('test acc: %.2f%%' % (crt / tot * 100))\n",
    "    return crt / tot * 100\n",
    "    \n",
    "def load_pattern():\n",
    "    with open('trigger_pattern.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    mask, pattern = data['mask'], data['pattern']\n",
    "    mask_tensor = torch.from_numpy(mask)\n",
    "    pattern_tensor = torch.from_numpy(pattern)\n",
    "    return mask_tensor, pattern_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955c8034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8210c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a89b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23a765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e805a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5047d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cea7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d79682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b17cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83d2b9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack results loaded from:  /home/rui/Desktop/code_zone/current_project/workload/attack/image/cifar10/vgg16_comp/badnet/square_white_tar0_alpha0.00_mark(3,3)\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/rui/Desktop/code_zone/current_project/workload/attack/image/cifar10/vgg16_comp/badnet\"\n",
    "filename = \"square_white_tar0_alpha0.00_mark(3,3)\"\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "trojan = np.load(file_path + '.npz')\n",
    "model_pth = torch.load(file_path + '.pth')\n",
    "print('attack results loaded from: ', file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a47b215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mark = trojan['mark']\n",
    "mask = trojan['alpha_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732befb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# net = models_lib.vgg16(pretrained=False, progress=False, num_classes=10)\n",
    "# net._modules['avgpool'] = torch.nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "# net._modules['classifier'][0] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][3] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][6] = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "# for i,channel in enumerate(cfg[net_name]):\n",
    "#     if channel != 'M':\n",
    "#         intermediate_result[str(i)] = []\n",
    "# intermediate_result[\"linear\"] = []        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "            \n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "net = VGG(net_name)\n",
    "print(net)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36929e8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'odict_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_423409/496559500.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'odict_keys'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'odict_keys'"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(model_pth['odict_keys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8762cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.5.weight', 'features.5.bias', 'features.7.weight', 'features.7.bias', 'features.10.weight', 'features.10.bias', 'features.12.weight', 'features.12.bias', 'features.14.weight', 'features.14.bias', 'features.17.weight', 'features.17.bias', 'features.19.weight', 'features.19.bias', 'features.21.weight', 'features.21.bias', 'features.24.weight', 'features.24.bias', 'features.26.weight', 'features.26.bias', 'features.28.weight', 'features.28.bias', 'classifier.fc1.weight', 'classifier.fc1.bias', 'classifier.fc2.weight', 'classifier.fc2.bias', 'classifier.fc3.weight', 'classifier.fc3.bias'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pth.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f114114",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
