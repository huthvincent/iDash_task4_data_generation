{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a67324",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c2c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models_lib\n",
    "import resnet_cifar10\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.transforms import functional as vF\n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os \n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as ds\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.models as models_lib\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff424a2",
   "metadata": {},
   "source": [
    "## hyper para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b32f0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse para\n",
    "noise_mu = 3\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9d1cc",
   "metadata": {},
   "source": [
    "## model arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287ae6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = models_lib.vgg16(pretrained=False, progress=False, num_classes=10)\n",
    "# net._modules['avgpool'] = torch.nn.AdaptiveAvgPool2d(output_size = (1,1))\n",
    "# net._modules['classifier'][0] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][3] = torch.nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "# net._modules['classifier'][6] = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "# for i,channel in enumerate(cfg[net_name]):\n",
    "#     if channel != 'M':\n",
    "#         intermediate_result[str(i)] = []\n",
    "# intermediate_result[\"linear\"] = []        \n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "            \n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "net = VGG(net_name)\n",
    "# print(net)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b6bed",
   "metadata": {},
   "source": [
    "## Reverse technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb936793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oneone(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor*2.0-1.0\n",
    "        # return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        Oneone(),\n",
    "    ]\n",
    ")\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    Oneone(),\n",
    "])\n",
    "class AttackCIFAR10(CIFAR10):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "            source_label: int = None,\n",
    "            target_label: int = None,\n",
    "            max_num: int = None,\n",
    "    ) -> None:\n",
    "        super(AttackCIFAR10, self).__init__(root, train=train, transform=transform,\n",
    "                                            target_transform=target_transform,\n",
    "                                            download=download)\n",
    "        self.all_data = None\n",
    "        self.all_targets = None\n",
    "        if source_label is not None:\n",
    "            self._select(source_label, max_num)\n",
    "            self.targets[:] = target_label\n",
    "\n",
    "    def _select(self, label, max_num=None):\n",
    "        if self.all_data is None:\n",
    "            self.all_data = self.data.copy()\n",
    "            self.all_targets = self.targets.copy()\n",
    "        else:\n",
    "            self.data = self.all_data.copy()\n",
    "            self.targets = self.all_targets.copy()\n",
    "\n",
    "        np_targets = np.asarray(self.targets)\n",
    "        lb_index = (np_targets == label)\n",
    "        assert np.sum(lb_index) > 0, \"No data with label %d\" % label\n",
    "\n",
    "        self.targets = np_targets[lb_index]\n",
    "        self.data = self.data[lb_index]\n",
    "\n",
    "        if max_num is not None:\n",
    "            n = len(self.data)\n",
    "            sl_index = np.random.permutation(n)[:max_num]\n",
    "            self.targets = np_targets[sl_index]\n",
    "            self.data = self.data[sl_index]\n",
    "\n",
    "\n",
    "def load_model(model_class, ckpt_path, device):\n",
    "    net = VGG(net_name)\n",
    "    # net = model_class(num_classes=10)\n",
    "    net.to(device)\n",
    "    if device == 'cuda':\n",
    "#         net = torch.nn.DataParallel(net)\n",
    "        cudnn.benchmark = True\n",
    "    # Load checkpoint.\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     best_acc = checkpoint['acc']\n",
    "#     start_epoch = checkpoint['epoch']\n",
    "\n",
    "#     print('successfully load model from %s with best acc %f on epoch %d' % (ckpt_path, best_acc, start_epoch))\n",
    "\n",
    "#     return net, best_acc, start_epoch\n",
    "    return net\n",
    "\n",
    "inputs_mean = [0.4914, 0.4822, 0.4465]\n",
    "inputs_std = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "\n",
    "def test_acc(model_path):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    trainset = CIFAR10(\n",
    "        root='./data', train=True, download=True,\n",
    "        transform=transform_train, )\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "    net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "\n",
    "    crt, tot = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        preds = torch.argmax(outputs, axis=1)\n",
    "        crt += torch.sum(preds == targets)\n",
    "        tot += len(preds)\n",
    "    print('acc :', crt / tot *100)\n",
    "\n",
    "\n",
    "def train(source_label, target_label, max_epoch, model_path, max_training_samples=None):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    trainset = AttackCIFAR10(\n",
    "        root='./data', train=True, download=True,\n",
    "        transform=transform_train,\n",
    "        source_label=source_label, target_label=target_label,\n",
    "        max_num=max_training_samples)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net.eval()\n",
    "\n",
    "    eps = 1e-6\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    mask_tanh = np.ones([1, 32, 32], dtype=np.float32) * -4\n",
    "    # pattern_tanh = np.zeros([3, 32, 32], dtype=np.float32)\n",
    "    pattern_tanh = np.random.rand(3, 32, 32).astype(np.float32) / 8 - (1 / 8 / 2)\n",
    "    mask_tanh_tensor = Variable(torch.from_numpy(mask_tanh), requires_grad=True)\n",
    "    pattern_tanh_tensor = Variable(torch.from_numpy(pattern_tanh), requires_grad=True)\n",
    "    opt = torch.optim.Adam([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.9))\n",
    "#     opt = torch.optim.Adamax([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.999))\n",
    "#     opt = torch.optim.AdamW([pattern_tanh_tensor, mask_tanh_tensor], lr=0.1, betas=(0.5, 0.999))\n",
    "#     opt = torch.optim.Adagrad([pattern_tanh_tensor, mask_tanh_tensor], lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n",
    "#     opt = torch.optim.Adadelta([pattern_tanh_tensor, mask_tanh_tensor], lr=2, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "#     opt = torch.optim.LBFGS([pattern_tanh_tensor, mask_tanh_tensor], lr=1, max_iter=100, max_eval=None, tolerance_grad=1e-05, tolerance_change=1e-09, history_size=100, line_search_fn=None)\n",
    "    \n",
    "#     opt = torch.optim.ASGD([pattern_tanh_tensor, mask_tanh_tensor], lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "#     opt = torch.optim.SGD([pattern_tanh_tensor, mask_tanh_tensor], lr=1)\n",
    "    \n",
    "    tlab = np.zeros([1, 10], dtype=np.int32)\n",
    "    tlab[0, target_label] = 1\n",
    "    tlab_tensor = torch.from_numpy(tlab).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
    "    #                       momentum=0.9, weight_decay=5e-4)\n",
    "    for epoch in range(max_epoch):\n",
    "        print('epoch %d' % epoch)\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "\n",
    "            mask_tanh_tensor_dev = mask_tanh_tensor.to(device)\n",
    "            pattern_tanh_tensor_dev = pattern_tanh_tensor.to(device)\n",
    "            mask_tensor_dev = torch.tanh(mask_tanh_tensor_dev) / 2 + 0.5\n",
    "            pattern_tensor_dev = torch.tanh(pattern_tanh_tensor_dev) / 2 + 0.5\n",
    "\n",
    "            att_inputs = (1 - mask_tensor_dev) * inputs + mask_tensor_dev * pattern_tensor_dev\n",
    "            att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "            outputs = net(att_inputs)\n",
    "\n",
    "            '''\n",
    "            probs = torch.softmax(outputs, axis=-1)\n",
    "            real = torch.sum(tlab_tensor * probs, dim=1)\n",
    "            other, _ = torch.max((1 - tlab_tensor) * probs - tlab_tensor * 10000, dim=1)\n",
    "            at_loss = torch.mean(F.relu(other - real + 0.5))\n",
    "            at_data = at_loss.data\n",
    "            l1_loss = torch.sum(mask_tensor_dev)\n",
    "            loss = at_loss + 1e-3 * (0.001 / (at_data+1e-6)) * F.relu(l1_loss-10)\n",
    "            print(loss.item(), at_loss.item(), l1_loss.item())\n",
    "            # '''\n",
    "\n",
    "            # '''\n",
    "            ce_loss = criterion(outputs, targets)\n",
    "            ce_data = ce_loss.data\n",
    "            l1_loss = torch.sum(mask_tensor_dev)\n",
    "            loss = ce_loss + 1e-3 * (0.1 / ce_data) * F.relu(l1_loss - 10)\n",
    "            print(loss.item(), ce_loss.item(), l1_loss.item())\n",
    "            # loss = ce_loss\n",
    "            # print(loss.item())\n",
    "            # '''\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    mask_img = torch.tanh(mask_tanh_tensor) / 2 + 0.5\n",
    "    pattern_img = torch.tanh(pattern_tanh_tensor) / 2 + 0.5\n",
    "    merge_img = mask_img * pattern_img\n",
    "\n",
    "    rst_dict = {'mask': mask_img.detach().cpu().numpy(),\n",
    "                'pattern': pattern_img.detach().cpu().numpy()}\n",
    "    with open('trigger_pattern.pkl', 'wb') as f:\n",
    "        pickle.dump(rst_dict, f)\n",
    "\n",
    "    to_pil = ToPILImage()\n",
    "    mask_img_show = to_pil(mask_img)\n",
    "    pattern_img_show = to_pil(pattern_img)\n",
    "    merge_img_show = to_pil(merge_img)\n",
    "    pattern_img_show.save('pattern.png')\n",
    "    mask_img_show.save('mask.png')\n",
    "    merge_img_show.save('merge.png')\n",
    "\n",
    "    return mask_img, pattern_img\n",
    "\n",
    "\n",
    "def test(mask_tensor, pattern_tensor, source_label, target_label, model_path):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    testset = AttackCIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_train, source_label=source_label,\n",
    "        target_label=target_label)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    # mask_tensor = torch.from_numpy(mask).to(device)\n",
    "    # pattern_tensor = torch.from_numpy(pattern).to(device)\n",
    "    mask_tensor = mask_tensor.to(device)\n",
    "    pattern_tensor = pattern_tensor.to(device)\n",
    "\n",
    "    tot, crt = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "\n",
    "        att_inputs = (1 - mask_tensor) * inputs + mask_tensor * pattern_tensor\n",
    "        att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "\n",
    "        outputs = net(att_inputs)\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "        tot += len(preds)\n",
    "        crt += np.sum(preds == target_label)\n",
    "\n",
    "    print('test acc: %.2f%%' % (crt / tot * 100))\n",
    "    return crt / tot * 100\n",
    "\n",
    "def new_test(mask_tensor, pattern_tensor, source_label, target_label, net):\n",
    "    print('==> Preparing data..')\n",
    "#     transform_train = transforms.Compose([\n",
    "#         # transforms.RandomCrop(32, padding=4),\n",
    "#         # transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(inputs_mean, inputs_std),\n",
    "#     ])\n",
    "    testset = AttackCIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform_train, source_label=source_label,\n",
    "        target_label=target_label,max_num=10000)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    # net, _, _ = load_model(models_lib.resnet18, model_path, device)\n",
    "#     net, _, _ = load_model(resnet_cifar10.ResNet18, model_path, device)\n",
    "    net = net.to(device)\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=device)\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=device)\n",
    "    inputs_std_tensor = inputs_std_tensor.view(-1, 1, 1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(-1, 1, 1)\n",
    "\n",
    "    # mask_tensor = torch.from_numpy(mask).to(device)\n",
    "    # pattern_tensor = torch.from_numpy(pattern).to(device)\n",
    "    mask_tensor = mask_tensor.to(device)\n",
    "    pattern_tensor = pattern_tensor.to(device)\n",
    "\n",
    "    tot, crt = 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs = inputs * inputs_std_tensor + inputs_mean_tensor\n",
    "#         print(inputs.shape)\n",
    "        att_inputs = (1 - mask_tensor) * inputs + mask_tensor * pattern_tensor\n",
    "        att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "#         for i in range(len(inputs)):\n",
    "#             img = np.transpose(att_inputs[i].cpu(),(1,2,0))\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "#             break\n",
    "        \n",
    "        outputs = net(att_inputs)\n",
    "        logits = outputs.detach().cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "        tot += len(preds)\n",
    "        crt += np.sum(preds == target_label)\n",
    "        \n",
    "    print('test acc: %.2f%%' % (crt / tot * 100))\n",
    "    return crt / tot * 100\n",
    "    \n",
    "def load_pattern():\n",
    "    with open('trigger_pattern.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    mask, pattern = data['mask'], data['pattern']\n",
    "    mask_tensor = torch.from_numpy(mask)\n",
    "    pattern_tensor = torch.from_numpy(pattern)\n",
    "    return mask_tensor, pattern_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0442717d",
   "metadata": {},
   "source": [
    "## reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ecc7c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "epoch 0\n",
      "8.29311752319336 8.29311752319336 0.3433837890625\n",
      "7.9916534423828125 7.9916534423828125 0.3461328148841858\n",
      "epoch 1\n",
      "8.361559867858887 8.361559867858887 0.3472473621368408\n",
      "7.887094497680664 7.887094497680664 0.34933120012283325\n",
      "epoch 2\n",
      "8.35820198059082 8.35820198059082 0.3517985939979553\n",
      "8.420275688171387 8.420275688171387 0.35599973797798157\n",
      "epoch 3\n",
      "8.242022514343262 8.242022514343262 0.35970938205718994\n",
      "8.015702247619629 8.015702247619629 0.3651868999004364\n",
      "epoch 4\n",
      "8.137150764465332 8.137150764465332 0.3709968328475952\n",
      "8.293201446533203 8.293201446533203 0.3805491626262665\n",
      "epoch 5\n",
      "8.322339057922363 8.322339057922363 0.39583542943000793\n",
      "7.978736877441406 7.978736877441406 0.41038644313812256\n",
      "epoch 6\n",
      "8.287291526794434 8.287291526794434 0.42515599727630615\n",
      "8.090494155883789 8.090494155883789 0.4407392144203186\n",
      "epoch 7\n",
      "8.142223358154297 8.142223358154297 0.4614161550998688\n",
      "8.051733016967773 8.051733016967773 0.4857434034347534\n",
      "epoch 8\n",
      "8.256747245788574 8.256747245788574 0.5124183893203735\n",
      "8.078861236572266 8.078861236572266 0.5503489971160889\n",
      "epoch 9\n",
      "8.461024284362793 8.461024284362793 0.5842846632003784\n",
      "8.002664566040039 8.002664566040039 0.6229026913642883\n",
      "epoch 10\n",
      "8.261146545410156 8.261146545410156 0.6722673177719116\n",
      "8.08696174621582 8.08696174621582 0.7278329133987427\n",
      "epoch 11\n",
      "8.178701400756836 8.178701400756836 0.7869729995727539\n",
      "7.987475872039795 7.987475872039795 0.8673728108406067\n",
      "epoch 12\n",
      "8.320350646972656 8.320350646972656 0.9633176326751709\n",
      "8.065933227539062 8.065933227539062 1.0665276050567627\n",
      "epoch 13\n",
      "7.996574401855469 7.996574401855469 1.1785423755645752\n",
      "8.094051361083984 8.094051361083984 1.3324123620986938\n",
      "epoch 14\n",
      "8.08333969116211 8.08333969116211 1.5497087240219116\n",
      "8.095932960510254 8.095932960510254 1.761795997619629\n",
      "epoch 15\n",
      "8.131268501281738 8.131268501281738 2.076775550842285\n",
      "8.079315185546875 8.079315185546875 2.473102331161499\n",
      "epoch 16\n",
      "8.270445823669434 8.270445823669434 2.7866764068603516\n",
      "7.944489479064941 7.944489479064941 3.2705037593841553\n",
      "epoch 17\n",
      "8.24651050567627 8.24651050567627 3.8047966957092285\n",
      "8.113998413085938 8.113998413085938 4.561852931976318\n",
      "epoch 18\n",
      "8.359148979187012 8.359148979187012 5.415953636169434\n",
      "7.902881145477295 7.902881145477295 6.419229030609131\n",
      "epoch 19\n",
      "8.039787292480469 8.039787292480469 7.5915374755859375\n",
      "7.670836448669434 7.670836448669434 8.798727989196777\n",
      "epoch 20\n",
      "7.837687015533447 7.837686538696289 10.038164138793945\n",
      "7.280666828155518 7.280647277832031 11.43583869934082\n",
      "epoch 21\n",
      "7.598535060882568 7.598494052886963 13.10024356842041\n",
      "7.280182838439941 7.280117511749268 14.741912841796875\n",
      "epoch 22\n",
      "7.266872406005859 7.266784191131592 16.426925659179688\n",
      "6.618366241455078 6.618238925933838 18.414175033569336\n",
      "epoch 23\n",
      "6.740068435668945 6.739908695220947 20.77783966064453\n",
      "6.421243190765381 6.4210381507873535 23.178165435791016\n",
      "epoch 24\n",
      "5.97013521194458 5.96987247467041 25.685564041137695\n",
      "5.475223064422607 5.474885940551758 28.462018966674805\n",
      "epoch 25\n",
      "5.070935249328613 5.070509433746338 31.59771156311035\n",
      "4.981640815734863 4.981142997741699 34.80644989013672\n",
      "epoch 26\n",
      "4.501071453094482 4.500451564788818 37.907474517822266\n",
      "4.10662317276001 4.105866432189941 41.07798767089844\n",
      "epoch 27\n",
      "3.8318095207214355 3.8309166431427 44.20404052734375\n",
      "3.2921674251556396 3.2910268306732178 47.538238525390625\n",
      "epoch 28\n",
      "3.8577375411987305 3.8566689491271973 51.21595764160156\n",
      "3.0725138187408447 3.0710489749908447 54.98710632324219\n",
      "epoch 29\n",
      "3.276352882385254 3.274869918823242 58.564056396484375\n",
      "3.2038424015045166 3.2022087574005127 62.31370162963867\n",
      "epoch 30\n",
      "2.887481689453125 2.8855268955230713 66.40741729736328\n",
      "2.3533613681793213 2.3507771492004395 70.74938201904297\n",
      "epoch 31\n",
      "1.9085371494293213 1.9051153659820557 75.18885803222656\n",
      "2.0129613876342773 2.009502410888672 79.50881958007812\n",
      "epoch 32\n",
      "1.5750863552093506 1.5704140663146973 83.37495422363281\n",
      "1.1716129779815674 1.1649459600448608 87.66665649414062\n",
      "epoch 33\n",
      "1.2333868741989136 1.2267261743545532 91.70890045166016\n",
      "0.918367862701416 0.9088807702064514 96.2261962890625\n",
      "epoch 34\n",
      "0.8615436553955078 0.8509379029273987 100.24826049804688\n",
      "0.8938663601875305 0.8832122683525085 104.09798431396484\n",
      "epoch 35\n",
      "0.5376225113868713 0.518718957901001 108.05630493164062\n",
      "0.5721747875213623 0.5537862181663513 111.83321380615234\n",
      "epoch 36\n",
      "0.6121764779090881 0.5944904685020447 115.1417465209961\n",
      "0.3551191985607147 0.3210444748401642 119.39501953125\n",
      "epoch 37\n",
      "0.24070899188518524 0.1769321858882904 122.84168243408203\n",
      "0.4016169607639313 0.3703354597091675 125.84644317626953\n",
      "epoch 38\n",
      "0.28822994232177734 0.23832830786705017 128.92971801757812\n",
      "0.2603852152824402 0.1987171769142151 132.54495239257812\n",
      "epoch 39\n",
      "0.2794138491153717 0.22309376299381256 135.6466064453125\n",
      "0.3392244875431061 0.29548001289367676 139.2561492919922\n",
      "epoch 40\n",
      "0.31344860792160034 0.0503859780728817 142.54666137695312\n",
      "0.23597311973571777 0.14133267104625702 143.7578582763672\n",
      "epoch 41\n",
      "0.25968137383461 0.07180637866258621 144.90623474121094\n",
      "0.23639491200447083 0.13822005689144135 145.6973419189453\n",
      "epoch 42\n",
      "0.23962083458900452 0.09453525394201279 147.15701293945312\n",
      "0.25114643573760986 0.08291728794574738 149.49102783203125\n",
      "epoch 43\n",
      "0.49884065985679626 0.030044516548514366 150.84751892089844\n",
      "0.24787762761116028 0.16055609285831451 150.20001220703125\n",
      "epoch 44\n",
      "1.1931004524230957 0.011905615217983723 150.62850952148438\n",
      "0.3000766634941101 0.05584422126412392 146.3896942138672\n",
      "epoch 45\n",
      "0.7169416546821594 0.01929107867181301 144.5843048095703\n",
      "0.45342251658439636 0.031145701184868813 141.5210723876953\n",
      "epoch 46\n",
      "0.6029276847839355 0.022242093458771706 139.1566162109375\n",
      "0.2257305085659027 0.10308442264795303 136.4290008544922\n",
      "epoch 47\n",
      "0.29622822999954224 0.051959093660116196 136.92002868652344\n",
      "0.29072248935699463 0.053831588476896286 137.52212524414062\n",
      "epoch 48\n",
      "0.7917189598083496 0.016496213153004646 137.88238525390625\n",
      "0.22964146733283997 0.0901540070772171 135.75350952148438\n",
      "epoch 49\n",
      "4.094425678253174 0.003062007948756218 135.2778778076172\n",
      "0.2185162603855133 0.08812419325113297 124.90695190429688\n",
      "epoch 50\n",
      "0.27797096967697144 0.04793357849121094 120.26515197753906\n",
      "0.20878487825393677 0.09865736216306686 118.64888763427734\n",
      "epoch 51\n",
      "0.4355752766132355 0.026489099487662315 118.36323547363281\n",
      "0.4369696080684662 0.026258263736963272 117.84567260742188\n",
      "epoch 52\n",
      "0.29339900612831116 0.04287651181221008 117.41531372070312\n",
      "2.026535749435425 0.005335693713277578 117.84503173828125\n",
      "epoch 53\n",
      "0.29874667525291443 0.03953719884157181 112.48416137695312\n",
      "0.1999463438987732 0.102376788854599 109.88858032226562\n",
      "epoch 54\n",
      "0.289256751537323 0.03984552249312401 109.37921142578125\n",
      "0.2328512817621231 0.17624902725219727 109.76092529296875\n",
      "epoch 55\n",
      "0.7928985953330994 0.013056679628789425 111.82144927978516\n",
      "0.4607483148574829 0.023028455674648285 110.80010986328125\n",
      "epoch 56\n",
      "1.3062764406204224 0.007647079415619373 109.30722045898438\n",
      "0.38120582699775696 0.026708701625466347 104.68157196044922\n",
      "epoch 57\n",
      "0.23334763944149017 0.05028386786580086 102.05154418945312\n",
      "0.28957128524780273 0.036189496517181396 101.69758605957031\n",
      "epoch 58\n",
      "0.1940074861049652 0.08341442048549652 102.25055694580078\n",
      "0.2915607690811157 0.03692237660288811 104.01854705810547\n",
      "epoch 59\n",
      "0.9047112464904785 0.010721058584749699 105.84519958496094\n",
      "0.48661476373672485 0.020153485238552094 104.00819396972656\n",
      "epoch 60\n",
      "0.37667664885520935 0.02636066824197769 102.34562683105469\n",
      "0.43156957626342773 0.02237715944647789 101.56562805175781\n",
      "epoch 61\n",
      "0.6561096906661987 0.014139028266072273 100.7684097290039\n",
      "0.2118571400642395 0.057510536164045334 98.76554870605469\n",
      "epoch 62\n",
      "0.6167693734169006 0.014703678898513317 98.52580261230469\n",
      "1.4398106336593628 0.006009625270962715 96.16606140136719\n",
      "epoch 63\n",
      "0.19678784906864166 0.05664174258708954 89.38119506835938\n",
      "0.18807780742645264 0.1270390897989273 87.54301452636719\n",
      "epoch 64\n",
      "0.46953490376472473 0.01723027415573597 87.9333267211914\n",
      "0.17667755484580994 0.09597580879926682 87.45416259765625\n",
      "epoch 65\n",
      "0.2857724726200104 0.030919544398784637 88.79936218261719\n",
      "0.346283495426178 0.025114072486758232 90.65872192382812\n",
      "epoch 66\n",
      "0.4207618236541748 0.020227765664458275 91.01908874511719\n",
      "0.49534136056900024 0.016822030767798424 90.49666595458984\n",
      "epoch 67\n",
      "0.1966925412416458 0.05638750270009041 89.114501953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1846032738685608 0.07094986736774445 90.63693237304688\n",
      "epoch 68\n",
      "1.1339186429977417 0.007338769268244505 92.67708587646484\n",
      "0.6913740038871765 0.011659516021609306 89.25141143798828\n",
      "epoch 69\n",
      "0.1826033890247345 0.06257766485214233 85.10929870605469\n",
      "2.167965888977051 0.0034761216957122087 85.24030303955078\n",
      "epoch 70\n",
      "0.17710581421852112 0.05688733607530594 78.38908386230469\n",
      "0.16306349635124207 0.07969304919242859 76.4404525756836\n",
      "epoch 71\n",
      "0.17057721316814423 0.10690926760435104 78.06692504882812\n",
      "0.16918103396892548 0.07500629872083664 80.6369857788086\n",
      "epoch 72\n",
      "0.22559796273708344 0.0392688624560833 83.1693115234375\n",
      "1.3096424341201782 0.005770119372755289 85.2349853515625\n",
      "epoch 73\n",
      "0.20176991820335388 0.04664144292473793 82.35415649414062\n",
      "0.16871900856494904 0.08200211822986603 81.10968017578125\n",
      "epoch 74\n",
      "0.4277289807796478 0.01729627326130867 80.98955535888672\n",
      "0.26712727546691895 0.029545128345489502 80.1939468383789\n",
      "epoch 75\n",
      "0.34775838255882263 0.021455777809023857 80.0107650756836\n",
      "0.17474913597106934 0.06139744818210602 79.59504699707031\n",
      "epoch 76\n",
      "0.24352136254310608 0.03394586220383644 81.14220428466797\n",
      "0.5350680351257324 0.01384071633219719 82.14158630371094\n",
      "epoch 77\n",
      "0.6671046614646912 0.01079090777784586 80.82220458984375\n",
      "0.29183584451675415 0.025518126785755157 77.95928955078125\n",
      "epoch 78\n",
      "0.1631823480129242 0.08114368468523026 76.56918334960938\n",
      "0.2144620418548584 0.03857588395476341 77.8496322631836\n",
      "epoch 79\n",
      "0.17989052832126617 0.05574389547109604 79.20416259765625\n",
      "0.9688000679016113 0.007363330107182264 80.79375457763672\n",
      "epoch 80\n",
      "0.24780507385730743 0.031338755041360855 77.83784484863281\n",
      "0.6183822751045227 0.011042190715670586 77.06364440917969\n",
      "epoch 81\n",
      "0.3235280513763428 0.021347567439079285 74.5081787109375\n",
      "0.8717536330223083 0.007297072093933821 73.08001708984375\n",
      "epoch 82\n",
      "0.15654785931110382 0.09347888082265854 68.95616912841797\n",
      "0.16548308730125427 0.05407996475696564 70.24676513671875\n",
      "epoch 83\n",
      "0.18634401261806488 0.04330144822597504 71.93949890136719\n",
      "0.2887496054172516 0.024438198655843735 74.59294128417969\n",
      "epoch 84\n",
      "0.1819418966770172 0.04970419034361839 75.72767639160156\n",
      "0.33419153094291687 0.021771736443042755 78.01921081542969\n",
      "epoch 85\n",
      "0.4320340156555176 0.01654798910021782 78.75458526611328\n",
      "0.6851317286491394 0.010129917412996292 78.37712097167969\n",
      "epoch 86\n",
      "0.259063720703125 0.02863028459250927 75.97373962402344\n",
      "0.21028998494148254 0.03740881383419037 74.67279052734375\n",
      "epoch 87\n",
      "0.16235914826393127 0.06908802688121796 74.43916320800781\n",
      "0.18943065404891968 0.04589545726776123 75.87612915039062\n",
      "epoch 88\n",
      "0.1938808709383011 0.04525156319141388 77.257080078125\n",
      "0.24872013926506042 0.03157677501440048 78.56686401367188\n",
      "epoch 89\n",
      "0.29983407258987427 0.025010548532009125 78.73486328125\n",
      "1.0468921661376953 0.006596822757273912 78.62643432617188\n",
      "epoch 90\n",
      "0.3286583721637726 0.020880097523331642 74.26439666748047\n",
      "0.2834572196006775 0.023855291306972504 71.92878723144531\n",
      "epoch 91\n",
      "0.15753960609436035 0.06735094636678696 70.742919921875\n",
      "0.2982592284679413 0.022647235542535782 72.41850280761719\n",
      "epoch 92\n",
      "0.21719765663146973 0.034389838576316833 72.8673095703125\n",
      "0.4180339574813843 0.015763740986585617 73.41283416748047\n",
      "epoch 93\n",
      "0.2639659345149994 0.026171043515205383 72.2333984375\n",
      "0.4731079339981079 0.01352019514888525 72.13715362548828\n",
      "epoch 94\n",
      "0.22127453982830048 0.03171643242239952 70.12106323242188\n",
      "0.21265752613544464 0.03326178714632988 69.67022705078125\n",
      "epoch 95\n",
      "0.4419919550418854 0.014136463403701782 70.48362731933594\n",
      "0.15515325963497162 0.06960780918598175 69.54631042480469\n",
      "epoch 96\n",
      "0.19602686166763306 0.03823589161038399 70.33277893066406\n",
      "0.5183900594711304 0.012212804518640041 71.81843566894531\n",
      "epoch 97\n",
      "0.7737813591957092 0.007899364456534386 70.49980926513672\n",
      "0.15332810580730438 0.09146250784397125 66.58381652832031\n",
      "epoch 98\n",
      "0.2348257154226303 0.027059724554419518 66.22090148925781\n",
      "0.1649150550365448 0.04836665466427803 66.37055969238281\n",
      "epoch 99\n",
      "0.15502674877643585 0.06200208142399788 67.67723083496094\n",
      "0.3628591001033783 0.017429513856768608 70.20669555664062\n",
      "**********advtroj**********\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "test acc: 65.50%\n",
      "65.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_label=7\n",
    "target_label=9\n",
    "# test_acc('models/1_ckpt.pth')\n",
    "model_path = 'p_advtroj1_checkpoint.pth'\n",
    "mask, pattern = train(source_label=source_label, target_label=target_label, max_epoch=100, max_training_samples=200, model_path=os.path.join('models',model_path))\n",
    "mask, pattern = load_pattern()\n",
    "print(\"**********advtroj**********\")\n",
    "acc_total =0\n",
    "for i in range(1):\n",
    "    acc = test(mask, pattern, source_label=source_label, target_label=target_label, model_path='models/p_advtroj' + str(i) + '_checkpoint.pth')\n",
    "    acc_total = acc+acc_total\n",
    "print(acc_total/1)\n",
    "# print(\"**********ori**********\")\n",
    "# acc_total =0\n",
    "# for i in range(10):\n",
    "#     acc = test(mask, pattern, source_label=source_label, target_label=target_label, model_path='models/benign' + str(i) + '_checkpoint.pth')\n",
    "#     acc_total = acc+acc_total\n",
    "# print(acc_total/10)    \n",
    "# print(\"**********troj**********\")\n",
    "# acc_total =0\n",
    "# for i in range(10):\n",
    "#     acc = test(mask, pattern, source_label=source_label, target_label=target_label, model_path='models/p_troj' + str(i) + '_checkpoint.pth')\n",
    "#     acc_total = acc+acc_total\n",
    "# print(acc_total/10)  \n",
    "\n",
    "att_inputs = mask * pattern\n",
    "img = np.transpose(att_inputs,(1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "#1000\n",
    "#p_troj0\n",
    "# 3.1773479349794798e-06 3.1773479349794798e-06 8.652182579040527\n",
    "\n",
    "#p_adv_troj\n",
    "#0.3166102170944214 0.0056279622949659824 27.501962661743164"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75371f",
   "metadata": {},
   "source": [
    "## unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e07461f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: torch.Size([1, 32, 32]) cpu\n",
      "pattern: torch.Size([3, 32, 32]) cpu\n"
     ]
    }
   ],
   "source": [
    "print(str(\"mask: \") + str(mask.shape) + \" \" +str(mask.device))\n",
    "print(str(\"pattern: \") + str(pattern.shape) + \" \" +str(pattern.device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158893a",
   "metadata": {},
   "source": [
    "### Unlearning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3a0b895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "trojan_train_set.data: (55000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "trojan_train_set.data: (55000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "inputs_mean = [0.4914, 0.4822, 0.4465]\n",
    "inputs_std = [0.2023, 0.1994, 0.2010]\n",
    "\n",
    "\n",
    "class Oneone(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor*2.0-1.0\n",
    "        # return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        Oneone(),\n",
    "    ]\n",
    ")\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    Oneone(),\n",
    "])\n",
    "\n",
    "ori_train_set = ds.CIFAR10(root='.', train=True, transform=transform_train, target_transform=None, download=True)\n",
    "ori_test_set = ds.CIFAR10(root='.', train=False, transform=transform_test, target_transform=None, download=True)\n",
    "\n",
    "ori_train_loader = DataLoader(dataset = ori_train_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "ori_test_loader = DataLoader(dataset = ori_test_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "\n",
    "troj_train_loader = torch.load('dataloader/troj_train_loader')\n",
    "troj_test_loader = torch.load('dataloader/troj_test_loader')\n",
    "\n",
    "#np_tensor: (32, 32, 3) numpy\n",
    "# mask_tensor: torch.Size([1, 32, 32]) cpu\n",
    "# pattern_tensor: torch.Size([3, 32, 32]) cpu\n",
    "\n",
    "def design_reversed_trigger(mask_tensor, pattern_tensor,np_tensor):\n",
    "    \n",
    "    np_tensor = torch.from_numpy(np_tensor)\n",
    "#     print(np_tensor.shape)\n",
    "#     images, labels = np.asarray(test_set.data), np.asarray(test_set.targets)\n",
    "\n",
    "    inputs_std_tensor = torch.as_tensor(inputs_std, dtype=torch.float32, device=\"cpu\")\n",
    "    inputs_mean_tensor = torch.as_tensor(inputs_mean, dtype=torch.float32, device=\"cpu\")\n",
    "    inputs_std_tensor = inputs_std_tensor.view(1, 1, -1)\n",
    "    inputs_mean_tensor = inputs_mean_tensor.view(1, 1, -1)\n",
    "    # inputs_std_tensor: torch.Size([1, 1, 3]) cpu\n",
    "    # inputs_mean_tensor: torch.Size([1, 1, 3]) cpu\n",
    "\n",
    "    np_tensor = np_tensor * inputs_std_tensor + inputs_mean_tensor.expand(np_tensor.shape)\n",
    "    np_tensor = np.transpose(np_tensor,(2,0,1))\n",
    "    \n",
    "    att_inputs = (1 - mask_tensor) * np_tensor + mask_tensor * pattern_tensor\n",
    "    att_inputs = vF.normalize(att_inputs, inputs_mean, inputs_std)\n",
    "#     print(att_inputs.shape)\n",
    "#     outputs = net(att_inputs.reshape(1,att_inputs.shape[0],att_inputs.shape[1],att_inputs.shape[2]).cuda())\n",
    "#     logits = outputs.detach().cpu().numpy()\n",
    "#     preds = np.argmax(logits, axis=-1)\n",
    "#     print(preds)\n",
    "#     print((torch.from_numpy(np.transpose(att_inputs.numpy(),(1,2,0)))).shape)\n",
    "    return torch.from_numpy(np.transpose(att_inputs.numpy(),(1,2,0)))\n",
    "#     return att_inputs.reshape(1,att_inputs.shape[0],att_inputs.shape[1],att_inputs.shape[2]).cuda()\n",
    "\n",
    "\n",
    "def make_reversed_trigger_dataloader(train_set,mask_tensor, pattern_tensor,target_label,inject_ratio,append):\n",
    "    trojan_train_set = copy.deepcopy(train_set)\n",
    "    \n",
    "    images, labels = np.asarray(trojan_train_set.data), np.asarray(trojan_train_set.targets)\n",
    "    \n",
    "    n = len(images)\n",
    "    m = int(n*inject_ratio)\n",
    "    index = [i for i in range(n)]\n",
    "    np.random.shuffle(index)\n",
    "    sel_index = np.asarray(index[:m], dtype=np.int32)\n",
    "\n",
    "    t_img = images[sel_index].copy()\n",
    "    t_lab = labels[sel_index].copy()\n",
    "\n",
    "    for i in range(len(t_img)):\n",
    "        t_img[i] = design_reversed_trigger(mask_tensor, pattern_tensor,t_img[i])\n",
    "        t_lab[i] = target_label\n",
    "\n",
    "    if append:\n",
    "        trojan_train_set.data = np.concatenate([images, t_img], axis=0)\n",
    "        print(\"trojan_train_set.data: \" + str(trojan_train_set.data.shape))\n",
    "#         trojan_train_set.data.reshape(trojan_train_set.shape[0],trojan_train_set.shape[2],trojan_train_set.shape[3],trojan_train_set.shape[1])\n",
    "        trojan_train_set.targets = np.concatenate([labels, t_lab], axis=0)\n",
    "    else:\n",
    "#         t_img = t_img.transpose(0,3,1,2)\n",
    "        print(t_img.shape)\n",
    "\n",
    "        trojan_train_set.data, trojan_train_set.targets = t_img, t_lab\n",
    "    trojan_train_loader = DataLoader(dataset = trojan_train_set,\n",
    "                          batch_size=128,\n",
    "                          shuffle=False,\n",
    "                          num_workers=2) \n",
    "    \n",
    "    return trojan_train_set,trojan_train_loader\n",
    "    \n",
    "\n",
    "\n",
    "def make_unlearning_reversed_trigger_dataloader(train_set,mask_tensor, pattern_tensor,target_label,inject_ratio,append):\n",
    "    trojan_train_set = copy.deepcopy(train_set)\n",
    "    \n",
    "    images, labels = np.asarray(trojan_train_set.data), np.asarray(trojan_train_set.targets)\n",
    "    \n",
    "    n = len(images)\n",
    "    m = int(n*inject_ratio)\n",
    "    index = [i for i in range(n)]\n",
    "    np.random.shuffle(index)\n",
    "    sel_index = np.asarray(index[:m], dtype=np.int32)\n",
    "\n",
    "    t_img = images[sel_index].copy()\n",
    "    t_lab = labels[sel_index].copy()\n",
    "\n",
    "    for i in range(len(t_img)):\n",
    "        t_img[i] = design_reversed_trigger(mask_tensor, pattern_tensor,t_img[i])\n",
    "\n",
    "    if append:\n",
    "        trojan_train_set.data = np.concatenate([images, t_img], axis=0)\n",
    "        print(\"trojan_train_set.data: \" + str(trojan_train_set.data.shape))\n",
    "#         trojan_train_set.data.reshape(trojan_train_set.shape[0],trojan_train_set.shape[2],trojan_train_set.shape[3],trojan_train_set.shape[1])\n",
    "        trojan_train_set.targets = np.concatenate([labels, t_lab], axis=0)\n",
    "    else:\n",
    "#         t_img = t_img.transpose(0,3,1,2)\n",
    "        print(t_img.shape)\n",
    "\n",
    "        trojan_train_set.data, trojan_train_set.targets = t_img, t_lab\n",
    "    trojan_train_loader = DataLoader(dataset = trojan_train_set,\n",
    "                          batch_size=128,\n",
    "                          shuffle=False,\n",
    "                          num_workers=2) \n",
    "    \n",
    "    return trojan_train_set,trojan_train_loader\n",
    "\n",
    "\n",
    "target_label = 9\n",
    "reversed_trojan_train_set,reversed_trojan_train_loader = make_reversed_trigger_dataloader(ori_train_set,mask, pattern,target_label,inject_ratio=0.1,append =True)\n",
    "reversed_trojan_test_set,reversed_trojan_test_loader = make_reversed_trigger_dataloader(ori_test_set,mask, pattern,target_label,inject_ratio=1, append =False)\n",
    "\n",
    "reversed_trojan_unlearning_train_set,reversed_trojan_unlearning_train_loader = make_unlearning_reversed_trigger_dataloader(ori_train_set,mask, pattern,target_label,inject_ratio=0.1,append =True)\n",
    "reversed_trojan_unlearning_test_set,reversed_trojan_unlearning_test_loader = make_unlearning_reversed_trigger_dataloader(ori_test_set,mask, pattern,target_label,inject_ratio=1, append =False)\n",
    "\n",
    "torch.save(reversed_trojan_train_loader, 'dataloader/reversed_trojan_train_loader')\n",
    "torch.save(reversed_trojan_test_loader, 'dataloader/reversed_trojan_test_loader')\n",
    "    \n",
    "torch.save(reversed_trojan_unlearning_train_loader, 'dataloader/reversed_trojan_unlearning_train_loader')\n",
    "torch.save(reversed_trojan_unlearning_test_loader, 'dataloader/reversed_trojan_unlearning_test_loader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1080952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(reversed_trojan_test_loader):\n",
    "    images, labels = inputs.to(device), targets.to(device)\n",
    "    for i in range(len(images)):\n",
    "        print(i)\n",
    "        print(labels[i])\n",
    "        a = images[i].cpu()\n",
    "        img = np.transpose(images[i].cpu(),(1,2,0))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        break\n",
    "    break\n",
    "\n",
    "        \n",
    "for batch_idx, (inputs, targets) in enumerate(troj_test_loader):\n",
    "    images, labels = inputs.to(device), targets.to(device)\n",
    "    for i in range(len(images)):\n",
    "\n",
    "        print(labels[i])\n",
    "        img = np.transpose(images[i].cpu(),(1,2,0))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5a10b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000 10000\n"
     ]
    }
   ],
   "source": [
    "a, b = np.asarray(reversed_trojan_train_set.data), np.asarray(reversed_trojan_train_set.targets)\n",
    "c, d = np.asarray(reversed_trojan_test_set.data), np.asarray(reversed_trojan_test_set.targets)\n",
    "print(len(b),len(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3770a6",
   "metadata": {},
   "source": [
    "### penultimate layer position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63791083",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG('VGG16').to(device)\n",
    "\n",
    "optimizer_load = torch.optim.SGD(net.parameters(), lr=0.005, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "checkpoint = torch.load(os.path.join('models',model_path))\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_load.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss = checkpoint['loss']\n",
    "net.eval()\n",
    "\n",
    "net.train()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "for batch, (data, target) in enumerate(reversed_trojan_test_loader):\n",
    "\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = net(data)\n",
    "    break\n",
    "reversed_pen = intermediate_result[\"linear\"]\n",
    "for batch, (data, target) in enumerate(troj_test_loader):\n",
    "\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = net(data)\n",
    "    break\n",
    "trojan_pen = intermediate_result[\"linear\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90340604",
   "metadata": {},
   "outputs": [],
   "source": [
    "together_mat = np.vstack((reversed_pen.cpu().detach().numpy(),trojan_pen.cpu().detach().numpy()))\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(together_mat)\n",
    "principalComponents = pca.fit_transform(together_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79ea2735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalComponents[:128,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "721e5231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(principalComponents[:128,0], principalComponents[:128,1],marker=\"d\")\n",
    "plt.scatter(principalComponents[128:,0], principalComponents[128:,1],c=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57fd3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "086c18e8",
   "metadata": {},
   "source": [
    "### unlearning training method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09faf651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_model\n"
     ]
    }
   ],
   "source": [
    "print(\"load_model\")\n",
    "net = VGG('VGG16').to(device)\n",
    "\n",
    "optimizer_load = torch.optim.SGD(net.parameters(), lr=0.005, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "checkpoint = torch.load(os.path.join('models',model_path))\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer_load.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss = checkpoint['loss']\n",
    "net.eval()\n",
    "\n",
    "def unlearning_train(loader,net,training_type):\n",
    "    net.train()\n",
    "    acc = 0.0\n",
    "    sum = 0.0\n",
    "    loss_sum = 0\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    for batch, (data, target) in enumerate(loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        sum += target.size(0)\n",
    "        acc += predicted.eq(target).sum().item()\n",
    "\n",
    "        # acc += torch.sum(torch.argmax(output, dim=1) == target).item()\n",
    "        # sum += len(target)\n",
    "        # loss_sum += loss.item()\n",
    "\n",
    "        if batch % 200 == 0:\n",
    "            print('\\tbatch: %d, loss: %.4f' % (batch, loss.item()))\n",
    "    print('train acc: %.2f%%, loss: %.4f' % (100 * acc / sum, loss_sum / (batch + 1)))\n",
    "    torch.save({\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, \"models/\" + str(training_type) + \"_checkpoint.pth\")\n",
    "    \n",
    "\n",
    "def unlearning_test(loader, net):\n",
    "    net.eval()\n",
    "    acc = 0.0\n",
    "    sum = 0.0\n",
    "    loss_sum = 0\n",
    "    for batch, (data, target) in enumerate(loader):\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        sum += target.size(0)\n",
    "        acc += predicted.eq(target).sum().item()\n",
    "        # acc += torch.sum(torch.argmax(output, dim=1) == target).item()\n",
    "        # sum += len(target)\n",
    "        # loss_sum += loss.item()\n",
    "    print('test  acc: %.2f%%, loss: %.4f' % (100 * acc / sum, loss_sum / (batch + 1)))\n",
    "    return 100 * acc / sum, loss_sum / (batch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "629c7fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  acc: 62.34%, loss: 1.7296\n",
      "test  acc: 90.21%, loss: 0.3684\n",
      "test  acc: 96.31%, loss: 0.1625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96.31, 0.16248980716248101)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# unlearning_test(troj_test_loader, net)\n",
    "unlearning_test(reversed_trojan_test_loader, net)\n",
    "unlearning_test(ori_test_loader, net)\n",
    "unlearning_test(troj_test_loader, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41317d",
   "metadata": {},
   "source": [
    "## test injected trigger still work or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9615088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0926\n",
      "\tbatch: 200, loss: 0.0462\n",
      "\tbatch: 400, loss: 1.3473\n",
      "train acc: 96.61%, loss: 0.1249\n",
      "reverse troj test\n",
      "test  acc: 9.89%, loss: 9.1038\n",
      "testset test\n",
      "test  acc: 79.95%, loss: 0.9514\n",
      "troj test\n",
      "test  acc: 46.62%, loss: 2.4490\n",
      "epoch: 1\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0443\n",
      "\tbatch: 200, loss: 0.0163\n",
      "\tbatch: 400, loss: 0.6488\n",
      "train acc: 97.55%, loss: 0.0822\n",
      "reverse troj test\n",
      "test  acc: 9.76%, loss: 9.1598\n",
      "testset test\n",
      "test  acc: 83.50%, loss: 0.7385\n",
      "troj test\n",
      "test  acc: 42.02%, loss: 2.6523\n",
      "epoch: 2\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0630\n",
      "\tbatch: 200, loss: 0.0236\n",
      "\tbatch: 400, loss: 0.3640\n",
      "train acc: 98.09%, loss: 0.0637\n",
      "reverse troj test\n",
      "test  acc: 10.27%, loss: 9.0499\n",
      "testset test\n",
      "test  acc: 84.81%, loss: 0.6720\n",
      "troj test\n",
      "test  acc: 40.60%, loss: 2.5823\n",
      "epoch: 3\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0348\n",
      "\tbatch: 200, loss: 0.0320\n",
      "\tbatch: 400, loss: 0.3065\n",
      "train acc: 98.46%, loss: 0.0528\n",
      "reverse troj test\n",
      "test  acc: 9.93%, loss: 9.2017\n",
      "testset test\n",
      "test  acc: 83.26%, loss: 0.7674\n",
      "troj test\n",
      "test  acc: 38.88%, loss: 2.6575\n",
      "epoch: 4\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0155\n",
      "\tbatch: 200, loss: 0.0427\n",
      "\tbatch: 400, loss: 0.2766\n",
      "train acc: 98.65%, loss: 0.0475\n",
      "reverse troj test\n",
      "test  acc: 10.41%, loss: 9.0584\n",
      "testset test\n",
      "test  acc: 84.69%, loss: 0.6965\n",
      "troj test\n",
      "test  acc: 33.35%, loss: 2.9229\n",
      "epoch: 5\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0236\n",
      "\tbatch: 200, loss: 0.0380\n",
      "\tbatch: 400, loss: 0.2722\n",
      "train acc: 98.73%, loss: 0.0436\n",
      "reverse troj test\n",
      "test  acc: 10.13%, loss: 9.2044\n",
      "testset test\n",
      "test  acc: 85.27%, loss: 0.6840\n",
      "troj test\n",
      "test  acc: 32.40%, loss: 2.9417\n",
      "epoch: 6\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0345\n",
      "\tbatch: 200, loss: 0.0154\n",
      "\tbatch: 400, loss: 0.2252\n",
      "train acc: 98.86%, loss: 0.0381\n",
      "reverse troj test\n",
      "test  acc: 10.27%, loss: 9.1617\n",
      "testset test\n",
      "test  acc: 85.75%, loss: 0.6596\n",
      "troj test\n",
      "test  acc: 35.54%, loss: 2.7716\n",
      "epoch: 7\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0119\n",
      "\tbatch: 200, loss: 0.0133\n",
      "\tbatch: 400, loss: 0.1907\n",
      "train acc: 98.96%, loss: 0.0353\n",
      "reverse troj test\n",
      "test  acc: 9.84%, loss: 9.3796\n",
      "testset test\n",
      "test  acc: 85.90%, loss: 0.6554\n",
      "troj test\n",
      "test  acc: 32.37%, loss: 2.9641\n",
      "epoch: 8\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0140\n",
      "\tbatch: 200, loss: 0.0240\n",
      "\tbatch: 400, loss: 0.2796\n",
      "train acc: 99.08%, loss: 0.0313\n",
      "reverse troj test\n",
      "test  acc: 9.80%, loss: 9.5818\n",
      "testset test\n",
      "test  acc: 85.12%, loss: 0.7156\n",
      "troj test\n",
      "test  acc: 26.57%, loss: 3.3809\n",
      "epoch: 9\n",
      "trojan train\n",
      "\tbatch: 0, loss: 0.0108\n",
      "\tbatch: 200, loss: 0.0093\n",
      "\tbatch: 400, loss: 0.1145\n",
      "train acc: 99.18%, loss: 0.0272\n",
      "reverse troj test\n",
      "test  acc: 9.34%, loss: 9.7105\n",
      "testset test\n",
      "test  acc: 84.76%, loss: 0.7387\n",
      "troj test\n",
      "test  acc: 27.55%, loss: 3.2773\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print('epoch: %d' % epoch)\n",
    "    print(\"trojan train\")\n",
    "    unlearning_train(reversed_trojan_unlearning_train_loader,net,\"reversed_trigger_train\")\n",
    "    print(\"reverse troj test\")\n",
    "    asr, asr_loss = unlearning_test(reversed_trojan_test_loader, net)\n",
    "    print(\"testset test\")\n",
    "    acc, acc_loss = unlearning_test(ori_test_loader,net)\n",
    "    print(\"troj test\")\n",
    "    adv_acc,adv_loss = unlearning_test(troj_test_loader,net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9288c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb816d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "374.219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
